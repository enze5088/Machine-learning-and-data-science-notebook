#+TITLE:     Note: Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation
#+AUTHOR:    MoozIiSP
#+DATE:      <2018-12-25 Tue>
#+SETUPFILE: theme-readtheorg.setup

* TODO Summary

* Annotations

** 著论
一个生物上的问题。

#+begin_quote
SIFT and HOG are blockwise orientation histograms,
a representation we could associate roughly with complex
cells in V1, *the first cortical area in the primate visual pathway* .
#+end_quote

主要视觉路径的第一个皮层区域？

视觉系统具有将外部世界的二维投射重构为三维世界的能力。

+文中的mAP一词，为"mean average precision"的缩写形式（其实这并不是很重要）。+

"shift-invariant model"是指什么特性呢？

#+begin_quote
The neocognitron, however, lacked a supervised training algorithm.
#+end_quote

神经认知机？虽然很棒，但是缺少一种监督训练算法吗？也就是说，没有一种判定模型好坏
的标准？

"stochastic gradient descent" 随机梯度下降是？

#+begin_quote
CNNs saw heavy use in the 1990s (e.g., [24]), but then fell out of fashion,
particularly in computer vision, with the rise of support vector machines.
#+end_quote

虽然在90年代，CNN使用广泛，但是随着SVM的出现而显得过时，尤其是在计算机视觉领域。
是如此吗？

#+begin_quote
The central issue can be distilled to the following: To what extent do the CNN
classification results on ImageNet *generalize* to object detection results on the
PASCAL VOC Challenge?
#+end_quote

模型的泛化能力，也就是将模型运用在新的数据集上是否仍有良好的性能表现。

"category-specific linear SVMs."
特定类别的线性支持向量机大概是SVM中的一种吧？

"The conventional solution to this problem is to use unsupervised pre-training,
followed by supervised fine-tuning (e.g., [29])."，参考论文29。

"that supervised pretraining on a large auxiliary dataset (ILSVRC), followed by
domain-specific fine-tuning on a small dataset (PASCAL),"，类似迁移学习啦，那么
什么是迁移学习呢？

"HOG-like"，定向梯度的直方图特征。

#+begin_quote
localizing objects with a deep network and training a high-capacity model with
only a small quantity of annotated detection data.
#+end_quote

用深度网络来定位目标，又用只有小量标注数据来训练高容量模型到底是什么鬼？那个高容
量模型是什么啊？高容量模型大概是指模型参数，具体的内容可以进一步参考这里[fn:1][fn:2]。

*** 检测方法
不像图像分类，检测需要在图像中对目标进行定位。

**** 帧定位
"One approach *frames localization* as a regression problem"，所以帧定位也被作为一
个回归问题咯？

**** 滑动窗口检测
"sliding-window detector"，滑动窗口检测，所以针对于之前的那个织物图像的瑕疵检测
可以提出更进一步的改进。首先，从直觉上，感受器（现在还不知道，先借用这个名词）的
视野大小（滑窗大小）以及视野中有效信息都会影响检测效果，例如说ResNet56网络是接受
227×227像素大小的图片作为输入，那么如果所要学习的特征在图像上的占比很小是不是会
影响图像的识别呢？因为主要是在输入和标签上做个映射，那么无关的内容或者上下文会影
响到检测效果吧（大误）。

#+begin_quote
CNNs have been used in *this way* for at least two decades, typically on
constrained object categories, such as faces [28, 33] and pedestrians [29].
#+end_quote

首先，该论文写于2014年，所以CNN已经这样使用（构建一个滑动窗口检测器）至少20年了，
一般在有限目标分类上。

#+begin_quote
*maintain high spatial resolution*, these CNNs typically only have two
convolutional and pooling layers.
#+end_quote

为了维持高空间分辨率，这些CNNs一般只有两个卷积层和池化层。

"receptive fields"，感知域。

"an open technical challenge"，什么叫做开放性的技术挑战？

"affine image warping"，仿射图像扭曲？

#+begin_quote
Figure 1 presents an overview of our method and highlights some of our
results.
#+end_quote

之后，再把图片奉上。这里是总结性质的图。图中，给定一个输入图像，从图像中提取大约
2k的region proposals，并扭曲到CNN模型所接受的尺寸，接着丢给分类器分类。

#+begin_quote
The only class-specific computations are a reasonably small *matrix-vector
product* and *greedy non-maximum suppression*.
#+end_quote

唯一的（？）特定类计算是相当小（reasonably small）的矩阵向量积和贪婪非最大抑制什
么玩意。

"(cf. [32])."，之前使用的局部特征是什么？参考论文32。

#+begin_quote
Can we gain insight into the representation learned by the CNN? Perhaps the
densely connected layers, with more than 54 million parameters, are the key?
#+end_quote

我们可以深入了解CNN学习的表征吗？或许拥有超过54百万参数的稠密连接层就是关键？那
么神经网络中的参数（结构）如何工作的？

"detection analysis tool of Hoiem et al."，来自Hoiem的检测分析工具。

#+begin_quote
As an immediate consequence of this analysis, we demonstrate that a simple
bounding box regression method significantly reduces mislocalizations, which are
the dominant error mode.
#+end_quote

从错误模式中，得出简单的边界盒回归方法可以显著地减少错误定位，而错误定位是主要的
错误模式。

** 使用R-CNN的目标检测
#+begin_quote
In this section, we present our design decisions for each module, describe their
test-time usage, detail how their parameters are learned, and show results on
PASCAL VOC 2010-12.
#+end_quote


该句相当于说明了接下来的论文内容结构为:
1. 每个模块是为什么这样设计；
2. 它们的测试用例；
3. 再详细阐述它们所学到的参数如何；
4. PASCAL VOC 2010-12的性能表现。

*** 模型设计
#+begin_quote
A variety of recent papers offer methods for generating category-independent
region proposals.
#+end_quote

what's generating category-independent region proposals? And proposals?


另外什么是 *selective search* ，其中RCNN是一种特殊的 *region proposal* 方法。并
且与之前的检测研究相比较，参阅"[32, 35]"。

文中的"4096-dimensional"是指？

#+begin_quote
using the Caffe [21] implementation of the CNN described by Krizhevsky et al.
[22].
#+end_quote

本文作者选择使用Caffe框架以及由Keizhevsky的卷积网络模型来识别 region proposal ，
具体的模型细节参阅[22]。


"mean-subtracted"大概是指均差。

#+begin_quote
We refer readers to [21, 22] for more network architecture details.
#+end_quote

更多的网络结构细节参见[21, 22].

#+begin_quote
Prior to warping, we dilate the tight bounding box so that at the warped size
there are exactly p pixels of warped image context around the original box (we
use p = 16).
#+end_quote

大概是讲如何扭曲变换图片来着，具体得去看作者的实验代码。

*** 测试时间检测？

IoU（intersection-over-union)是什么？

**** Run-time analysis
#+begin_quote
such as spatial pyramids with *bag-of-visual-word encodings*.
#+end_quote

空间金字塔是什么鬼，另外 *bag-of-visual-word encodings* 是什么？

"UVA detection system"是指？

#+begin_quote
only class-specific computations are dot products between features and SVM
weights and non-maximum suppression
#+end_quote

这段数学描述不是很懂。

#+begin_quote
The feature matrix is typically 2000 4096 and the SVM weight matrix is 4096 N where N is the number of classes.
#+end_quote

同上，毫无头绪。

"resulting"，是什么鬼单词，有这种用法吗？


#+begin_quote
This analysis shows that R-CNN can scale to thousands of object classes without
resorting to approximate techniques, such as *hashing*.
#+end_quote

喵喵喵？hashing是什么黑科技？

*** Traning

**** Supervised pre-training
#+begin_quote
due to simplifications in the training process.
#+end_quote

怎么做到简化训练过程呢？

**** Domain-specific fine-tuning
"1000-way"应该等同于"1000 classes"。

#+begin_quote
We bias the sampling towards positive windows because they are extremely rare
compared to background.
#+end_quote

为什么它们相对于背景是极其少见的？

**** Object category classifiers
"IoU overlap threshold" (Girshick et al 2014:583)

#+begin_quote
We resolve this issue with an IoU overlap threshold, *below which* regions are
defined as negatives.
#+end_quote

"below which"是非限定性定语从句吗？

#+begin_quote
We found that selecting this threshold carefully is important.
#+end_quote

选择一个阈值很重要，因为会导致不同的结果。原因如下：

#+begin_quote
Setting it to 0.5, as in [32], decreased mAP by 5 points. Similarly, setting it
to 0 decreased mAP by 4 points. Positive examples are defined simply to be the
*ground-truth* bounding boxes for each class.
#+end_quote

"ground-truth"是基础真值的意思吗？

#+begin_quote
"standard hard negative mining method [14, 30]." (Girshick et al 2014:583)
#+end_quote

原文是采用这种方法来降低对内存的要求。该方法的行为如下：

#+begin_quote
standard hard negative mining method [14, 30]. Hard negative mining converges
quickly and in practice mAP stops increasing *after only a single pass over all
images*.
#+end_quote

啥意思？对所有图片只传递一次之后就停止增长？

#+begin_quote
it's necessary to train detection classifiers rather than simply use outputs
from the final layer (fc8) of the fine-tuned CNN.
#+end_quote

参见补充材料，并且也讨论了相比微调vsSVM训练是很能定义阳和阴的例子。

** PASCAL VOC 2010-12 结果

"SegDPM" (Girshick et al 2014:583)

"inter-detector context" (Girshick et al 2014:583)

什么东西 (note on p.583)


"spatial pyramid" (Girshick et al 2014:583)

"populates it with densely sampled SIFT, Extended OpponentSIFT, and RGBSIFT descriptors" (Girshick et al 2014:583)

"a histogram intersection kernel SVM" (Girshick et al 2014:583)

** 可视化，解剖和错误模式

*** 特征可视化

"[22]" (Girshick et al 2014:583)

"opponent colors" (Girshick et al 2014:583)

反色？ (note on p.583)


"Zeiler and Fergus present a visually attractive deconvolutional approach in [36]." (Girshick et al 2014:583)

"a simple (and complementary) non-parametric method that directly shows what the network learned." (Girshick et al 2014:583)

"in its own right" (Girshick et al 2014:583)

in one's own right (note on p.583)


""speak for itself" (Girshick et al 2014:583)

"fires on" (Girshick et al 2014:583)

"displays the top 16 activations for a pool5 unit" (Girshick et al 2014:583)

"class-tuned features" (Girshick et al 2014:584)

什么玩意 (note on p.584)

*** 研究剖析

"To understand which layers are critical for detection performance" (Girshick et al 2014:584)

问题 (note on p.584)


"half-wave rectified" (Girshick et al 2014:584)

"reveals that features from fc 7 generalize worse than features from fc6 ." (Girshick et al 2014:584)

"Much of the CNN's representational power comes from its convolutional layers, rather than from" (Girshick et al 2014:584)

"in the sense of" (Girshick et al 2014:585)

"enable experimentation with" (Girshick et al 2014:585)

"DPM" (Girshick et al 2014:585)

"striking" (Girshick et al 2014:585)

"The boost from fine-tuning is much larger for fc6 and fc7 than for pool5" (Girshick et al 2014:585)

这里是说微调基本只对模型中后几个全连接层有影响，而之前的池化层则影响不大 (note on p.585)


"The first DPM feature learning method" (Girshick et al 2014:585)

"random forest 25 25 25" (Girshick et al 2014:585)

"The second method, DPM HSC [27] total fa total fa total fa" (Girshick et al 2014:585)

"histograms of sparse codes (HSC)" (Girshick et al 2014:585)

""sketch token"" (Girshick et al 2014:585)

什么意思 (note on p.585)


"Intuitively, a sketch token is a tight distriBG BG BG bution of contours passing through the center of an image patch." (Girshick et al 2014:585)

what (note on p.585)


"spatially pooled, unit '2 normalized, and then power transformed (x sign(x)jxj)." (Girshick et al 2014:585)

"open source version [17]" (Girshick et al 2014:585)

"A full summary of the analysis tool is beyond the scope of this paper and we encourage readers to consult [20] to understand some finer details (such as "normalized AP")" (Girshick et al 2014:585)

*** 检测错误分析

"false positive" (Girshick et al 2014:585)

"indicating that the CNN features are much more discriminative than HOG." (Girshick et al 2014:585)

"positional invariance learned from pre-training the CNN for whole-image classification." (Girshick et al 2014:585)

why (note on p.585)

*** 边界盒回归

"Inspired by the bounding box regression employed in DPM [14]" (Girshick et al 2014:585)

"given" (Girshick et al 2014:585)

who gives? (note on p.585)

** 语义分割

"Region classification is a standard technique for semantic segmentation" (Girshick et al 2014:585)

"the current leading semantic segmentation system (called O2 P for "second-order pooling") [4]" (Girshick et al 2014:586)

"CPMC" (Girshick et al 2014:586)

"the powerful second-order pooling of multiple feature types (enriched variants of SIFT and LBP)." (Girshick et al 2014:586)

"follow [2, 4]" (Girshick et al 2014:586)

"include the extra annotations made available by Hariharan et al. [19]" (Girshick et al 2014:586)

"Design decisions and hyperparameters" (Girshick et al 2014:586)

"cross-validated" (Girshick et al 2014:586)

how to cross-validated? (note on p.586)


"The first strategy (full) ignores the region's shape and computes CNN features directly on the warped window, exactly as we did for detection." (Girshick et al 2014:586)

"these features ignore the non-rectangular shape of the region" (Girshick et al 2014:586)

"the second strategy (fg) computes CNN features only on a region's foreground mask." (Girshick et al 2014:586)

区域的前景模板上？ (note on p.586)


"We replace the background with the mean input so that background regions are zero after mean subtraction." (Girshick et al 2014:586)

Method (note on p.586)


"simply concatenates the full and fg features" (Girshick et al 2014:586)

"SVRs" (Girshick et al 2014:586)

"outperforms fc7" (Girshick et al 2014:586)

搞那么多全链接层不是很蛤币 (note on p.586)


"indicating that the masked region shape provides a stronger signal, matching our intuition." (Girshick et al 2014:586)

"margin of 4.2%" (Girshick et al 2014:586)

4.2%的差数，这里与fg方法相比较 (note on p.586)


"Still better performance could likely be achieved by fine-tuning." (Girshick et al 2014:586)

虽然会与O2P不相上下，但是微调仍可能实现更好的性能 (note on p.586)

** Conclusion

"low-level image features with high-level context" (Girshick et al 2014:586)

低级图像特征诸如边缘balabala，那么高级上下文特征是？ (note on p.586)


"scene classifiers" (Girshick et al 2014:586)

what's this? (note on p.586)


"two insights" (Girshick et al 2014:586)

"first is to apply high-capacity convolutional neural networks to bottom-up region proposals in order to localize and segment objects" (Girshick et al 2014:586)

高容量的卷积神经网络的“高容量”是什么意思？ (note on p.586)


"second is a paradigm for train-" (Girshick et al 2014:586)

"ing large CNNs when labeled training data is scarce." (Girshick et al 2014:587)

迁移学习呗 (note on p.587)


"with supervision" (Girshick et al 2014:587)

pre-train是什么鬼，不是都迁移了吗？合着你们直接自己训练一遍模型，而不是直接用现成的？ (note on p.587)


"the "supervised pre-training/domain-specific finetuning" paradigm will be highly effective for a variety of data-scarce vision problems." (Girshick et al 2014:587)

这是你们先发现的？？？可怕 (note on p.587)


"Rather than opposing lines of scientific inquiry, the two are natural and inevitable partners." (Girshick et al 2014:587)
* 一些术语名词
** SIFT
** HOG
** SVM
* Footnotes

[fn:1] [[https://stats.stackexchange.com/questions/312424/what-is-the-capacity-of-a-machine-learning-model][What is the “capacity” of a machine learning model?]]

[fn:2] [[https://stackoverflow.com/questions/40337510/what-is-the-definition-of-high-capacity-cnn-or-high-capacity-architecture][What is the definition of “high-capacity cnn” or “high-capacity architecture”?]]
