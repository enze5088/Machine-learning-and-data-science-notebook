# LINE：大规模网络信息嵌入

**LINE︰ Large-Information NetworkEmbedding**
Jian Tang1,Meng Qu2, MingzheWang∗, Ming Zhang2, Jun Yan1,Qiaozhu Mei3

1MicrosoftResearch Asia, {jiatang,junyan}@microsoft.com

2School ofEECS, Peking University, {mnqu, wangmingzhe, mzhang_cs}@pku.edu.cn

3School ofInformation, University of Michigan, qmei@umich.edu



摘要：本文研究了将非常大的信息网络嵌入到低维向量空间中的问题，该问题在可视化、节点分类和链路预测等任务中具有重要的应用价值。现有的图形嵌入方法大多不适用于通常包含数百万节点的真实信息网络。本文提出了一种新的网络嵌入方法，称为LINE，它适用于任意类型的信息网络:无向、有向和/或加权。该方法优化了一个精心设计的目标函数，同时保留了本地和全局网络结构。针对经典随机梯度下降法的局限性，提出了一种边缘采样算法，提高了推理的有效性和效率。实证实验证明了这条线在各种真实信息网络上的有效性，包括语言网络、社交网络和引文网络。该算法是非常有效的，它能够学习在一个典型的单机上在几个小时内嵌入一个具有数百万个顶点和数十亿条边的网络。这一行的源代码可以在网上找到。

一、 介绍

信息网络在现实世界中无处不在，例如航空公司网络、出版物网络、社交和通信网络以及万维网。这些信息网络的规模从数百个节点到数百万个节点不等。对大型信息网络的分析越来越受到学术界和工业界的重视。摘要研究了将信息网络嵌入低维空间的问题，在低维空间中，每个顶点都表示为一个低维向量。这种低维嵌入在可视化[21]、节点分类[3]、链接预测[10]、推荐[23]等多种应用中非常有用。

机器学习文献(e.g.，[4,20,2])提出了各种各样的图形嵌入方法。它们通常在较小的网络上表现良好。当涉及到包含数百万节点和数十亿边缘的真实世界信息网络时，问题就变得更具挑战性。例如，Twitter的follow-follower网络在2012年拥有1.75亿活跃用户和大约200亿边缘用户。大多数现有的图嵌入算法并不适用于这种规模的网络。例如，经典的图嵌入算法，如MDS[4]、异构映射[20]、拉普拉斯特征映射[2]，其时间复杂度至少是顶点数的二次函数，这对于具有数百万节点的网络来说代价太大。虽然最近有一些关于大规模网络嵌入的研究，但是这些方法要么使用的是一种非为网络设计的间接方法(如[1])，要么缺乏针对网络嵌入的明确的目标函数(如[16])。我们期望一个具有精心设计的目标函数来保持图的性质的新模型，以及一种有效的优化技术，能够有效地找到数百万节点的嵌入。

本文提出了一种网络嵌入模型 LINE。它可以扩展到非常大的，任意类型的网络:无向，有向和/或加权。该模型优化了保持局部网络结构和全局网络结构的目标。自然地，局部结构由网络中观察到的链路表示，这些链路捕获顶点之间的一阶近似。现有的大多数图嵌入算法都是为了保持这种一阶邻近性而设计的，例如异构映射[20]和拉普拉斯特征映射[2]，即使它们没有缩放。我们观察到，在真实的网络中，许多(如果不是大多数)合法链接实际上没有被观察到。换句话说，在真实世界的数据中观测到的一阶近似并不足以保持全局网络结构。作为补充，我们研究了顶点之间的二阶邻近性，它不是通过观察到的连接强度来确定的，而是通过顶点的共享邻域结构来确定的。二阶邻近性的一般概念可以解释为共享邻居可能相似的节点。这种直觉可以在社会学和语言学的理论中找到。例如，在社交网络[6]中，“两个人的友谊网络的重叠程度与他们之间的联系强度相关”;在文本语料库[5]中，“你应该从它的朋友那里知道一个词”(Firth, J. R. 1957:11)。事实上，拥有许多共同的朋友的人很可能会有相同的兴趣，成为朋友，和许多相似的词一起使用的词很可能有相似的含义。

> ![1543411128948](F:\Machine-learning-and-data-science-notebook\images\LINE\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1543411128948.png)
>
> 图1:一个玩具信息网络的例子。边缘可以是非有向的、有向的和/或加权的。顶点6和顶点7应该被紧密地放置在低维空间中，因为它们是通过一个强有力的纽带连接在一起的。顶点5和6也应该被放置得很近，因为它们共享相似的邻居。

图1给出了一个说明性的例子。由于顶点6与7之间的边权值较大，即， 6和7的一阶邻近性较高，在嵌入空间中应紧密表示。另一方面，虽然顶点5和6之间没有联系，但它们有许多共同的邻域，即，它们具有较高的二阶邻近性，因此也应该彼此密切表示。我们期望二阶近似的考虑能有效地补充一阶近似的稀疏性，更好地保持网络的全局结构。在本文中，我们将提出精心设计的目标，以保持一级和二级接近性。

即使找到了一个合理的目标，为一个非常大的网络优化它也是一个挑战。利用随机梯度下降法进行优化是近年来备受关注的一种方法。然而，我们证明了在真实的信息网络中直接采用随机梯度下降法是有问题的。这是因为在许多网络中，边是加权的，而且权值通常具有很大的方差。考虑一个单词共现网络，其中单词对的权重(共现)可能从1到数十万。这些边的权值会被乘以梯度，导致梯度的爆炸，从而影响性能。为了解决这一问题，我们提出了一种新的边缘采样方法，提高了推理的有效性和效率。我们对概率与权重成比例的边缘进行采样，然后将采样的边缘作为二值边缘进行模型更新。在这个采样过程中，目标函数保持不变，边缘的权重不再影响梯度。

LINE非常通用，即使找到了一个合理的目标，它也可以很好地用于定向，为非常大的网络优化它是一个挑战。利用随机梯度下降法进行优化是近年来备受关注的一种方法。然而，我们证明了在真实的信息网络中直接采用随机梯度下降法是有问题的。这是因为在许多网络中，边是加权的，而且权值通常具有很大的方差。考虑一个单词共现网络，其中单词对的权重(共现)可能从1到数十万。这些边的权值会被乘以梯度，导致梯度的爆炸，从而影响性能。为了解决这一问题，我们提出了一种新的边缘采样方法，提高了推理的有效性和效率。我们对概率与权重成比例的边缘进行采样，然后将采样的边缘作为二值边缘进行模型更新。在这个采样过程中，目标函数保持不变，边缘的权重不再影响梯度。

总之，我们做出了以下贡献

- 我们提出了一种新的网络嵌入模型，称为线，它适用于任意类型的信息网络，并且很容易扩展到数百万个节点。它有一个精心设计的目标函数，既保留了一阶相似度，也保留了二阶相似度。
- 我们提出了一种边缘采样算法来优化目标。该算法克服了经典随机梯度算法的局限性，提高了推理的有效性和效率。
- 我们在真实世界的信息网络上进行了广泛的实验。实验结果验证了该模型的有效性和有效性。

**组织：**本文的其余部分组织如下。第二部分对相关工作进行了总结。第三节正式定义了大规模信息网络嵌入问题。第四部分详细介绍了直线模型。第五部分给出了实验结果。最后，我们在第6节中总结。

## 2 相关工作

我们的工作涉及到一般的经典的图像嵌入或降维方法，如多维标度(MDS)[4]，异构化[20]，LLE[18]和拉普拉斯特征映射[2]。这些方法通常首先利用数据点的特征向量构造亲和图，例如数据的k近邻图，然后将亲和图[22]嵌入低维空间。然而，这些算法通常依赖于求解亲和矩阵的主导特征向量，其复杂度至少是节点数的二次型，使得它们在处理大规模网络时效率低下。

最近的文献中有一种技术叫做图分解[1]。利用随机梯度下降法，通过矩阵分解求出大图的低维嵌入。这是可能的，因为图可以表示为亲和矩阵。然而，矩阵分解的目标并不是为网络设计的，因此并不一定要保留全局网络结构。直观地说，图分解期望节点具有更高的一阶邻近性。相反，直线模型使用的目标是专门为网络设计的，它既保留了一级代理，也保留了二级代理。在实际应用中，图分解方法只适用于无向图，而所提出的模型适用于无向图和有向图。

最近与我们相关的工作是DeepWalk[16]，它为嵌入社交网络部署了一个截断的随机游走。虽然从经验上讲是有效的，但是深度行走并没有提供一个清晰的目标来阐明哪些网络属性被保留下来。从直觉上讲，DeepWalk期望二阶邻近度更高的节点产生类似的低维表示，而这条线同时保留了一阶和二阶代理。DeepWalk使用随机游走来扩展顶点的邻域，这类似于深度优先搜索。我们采用广度优先的搜索策略，这是一种更合理的二阶逼近方法。在实际应用中，深度遍历只适用于未加权网络，而我们的模型适用于具有加权和未加权边的网络。

在第5节中，我们使用各种真实世界网络对所提出的模型与这些方法进行了实证比较。

3 问题定义

我们正式定义了利用一阶和二阶代理嵌入大规模信息网络的问题。我们首先定义一个信息网络如下	

## 4 LINE:大规模信息网络嵌入

一种适用于现实信息网络的理想的嵌入模型必须满足以下几个要求:首先，它必须能够同时保持顶点之间的一阶邻近性和二阶邻近性;其次，它必须适用于非常大的网络，比如数百万个顶点和数十亿条边;第三，它可以处理任意类型的边缘网络:有向、无向和/或加权。在这一部分，我们提出了一种新的网络嵌入模型，称为LINE，它满足所有这三个要求。

### 4.1 模型描述

我们分别描述了保持一阶接近性和二阶接近性的直线模型，然后介绍了一种将这两种接近性结合起来的简单方法。

定义1。(信息网络)信息网络定义为G = (V, E)，其中V是顶点的集合，每个顶点代表一个数据对象，E是顶点之间的边的集合，每个边代表两个数据对象之间的关系。每条边e e是一个有序对e = (u, v)，与权值wuv > 0相关联，表示关系的强度。如果G是无向的，我们有(u, v) (v, u)和wuv wvu;如果G是定向的，我们有(u, v) 6 (v, u)和wuv 6 wvu。

#### 4.1.1 一阶近似直线

一阶邻近性是指网络中顶点之间的局部成对邻近性。为了对一阶邻近度建模，对于每条无向边(i, j)，我们定义顶点vi与vj的联合概率如下: