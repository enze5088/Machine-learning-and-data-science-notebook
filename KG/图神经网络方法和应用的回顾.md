# 图神经网络方法和应用的回顾

Jie Zhou∗, Ganqu Cui∗, Zhengyan Zhang∗, Cheng Yang, Zhiyuan Liu, Maosong Sun

**摘要**：很多学习任务都需要处理包含元素间丰富关系信息的图形数据。物理系统的建模、分子指纹的学习、蛋白质界面的预测、疾病的分类等都需要模型从图形输入中学习。在文本和图像等非结构数据的学习等其他领域，对提取的结构进行推理，如句子的依赖树和图像的场景图，是一个重要的研究课题，也需要图形推理模型。图神经网络(GNNs)是一种连接主义模型，它通过在图的节点之间传递消息来获取图的依赖性。与标准神经网络不同的是，图神经网络保留了一种状态，这种状态可以用任意深度表示邻居的信息。虽然原始图神经网络很难训练成定点，但是最近在网络结构、优化技术和并行计算方面的进展使得利用它们进行成功的学习成为可能。近年来，基于图卷积网络(GCN)和门控图神经网络(GGNN)的系统在上述许多任务上都表现出了突破性的性能。在这次调查中，我们对现有的图形神经网络模型进行了详细的回顾，系统地对其应用进行了分类，并提出了四个有待进一步研究的问题。

## 1 介绍

图形是对一组对象(节点)及其关系(边)建模的一种数据结构。最近,研究分析图表和机器学习已经收到越来越多的关注,因为图形的表达能力,即图可以作为外延大量系统在各个领域包括社会科学(社交网络)[33],[46],自然科学(物理系统[5],[77]和蛋白质相互作用网络[27]),知识图表(32)和许多其他研究领域[23]。图分析作为机器学习中一种独特的非欧几里得数据结构，其研究重点是节点分类、链路预测和聚类。图神经网络是一种基于图域的深度学习方法。由于其令人信服的性能和较高的可解释性，GNN近年来已成为一种广泛应用的图形分析方法。在下面的段落中，我们将阐述图形神经网络的基本动机。

GNNs的第一个动机来源于卷积神经网络(CNNs)[50]。CNNs具有提取多尺度局部空间特征并将其组合成高表达性表征的能力，这使得几乎所有的机器学习领域都出现了突破，开启了深度学习[49]的新时代。然而，CNNs只能对图像(2D网格)、文本(1D序列)等常规欧几里德数据进行操作，而这些数据结构可视为图形的实例。随着我们对CNNs和图形的深入研究，我们发现了CNNs的关键:本地连接、共享权重和多层[49]的使用。这些对于解决图域问题也很重要，因为图是最典型的局部连通结构。2)与传统的谱图理论[20]相比，共享权降低了计算成本。3)多层结构是处理分层模式的关键，它捕捉不同大小的特征。因此，很容易想到将cnn推广到图形。但是，如1所示，局部卷积滤波器和池运算很难定义，这阻碍了CNN从欧几里得域向非欧几里得域的转换。

> ![1545704679065](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545704679065.png)
>
> 图1所示。左:欧几里得空间中的图像。右:非欧几里德空间中的图

另一个动机来自于图的嵌入，它学习在低维向量中表示图的节点、边或子图。在图论分析领域，传统的机器学习方法通常依赖于人工工程的特征，但由于其不灵活性和高成本而受到限制。DeepWalk[70]是第一个基于表示学习的图形嵌入方法，它遵循表示学习的思想和单词嵌入的成功之处，将节点作为单词，在图形上生成的随机游动作为句子，然后对它们应用SkipGram模型[62]。node2vec[31]、LINE[89]、SDNE[96]等类似方法也取得了突破。然而，这些方法可能在计算上很昂贵，而且对于大型图来说也不是最优的。gnn就是为了解决这些问题而设计的。

基于网络神经网络和图形嵌入技术，提出了基于网络神经网络的图形神经网络(GNNs)，用于从图形结构中综合信息。因此，它们可以对由元素及其依赖性组成的输入和/或输出建模。此外，图神经网络可以同时用RNN核对图上的扩散过程进行建模。

在接下来的部分中，我们解释了为什么图形神经网络值得研究的基本原因。首先，标准的神经网络如CNNs和RNNs不能很好地处理图形输入，因为它们按照特定的顺序将节点的特征进行叠加。然而，在图中并没有节点的自然顺序。为了完整的呈现一个图，我们应该遍历所有可能的顺序作为模型的输入，比如CNNs和RNNs，这在计算时是非常冗余的。为了解决这个问题，gnn分别在每个节点上传播，忽略节点的输入顺序。也就是说，GNNs的输出对于节点的输入顺序是不变的。其次，图中的一条边表示两个节点之间依赖关系的信息。在标准神经网络中，依赖信息仅仅被视为节点的特征。但是，GNNs可以根据图结构进行传播，而不是将其作为特性的一部分。一般来说，gnn通过对节点邻域状态的加权和来更新节点的隐藏状态。第三，推理是高水平人工智能的一个非常重要的研究课题，人类大脑的推理过程几乎是基于从日常经验中提取出来的图形。标准的神经网络已经显示出通过学习数据的分布来生成合成图像和文档的能力，但仍然不能从大型实验数据中学习推理图。然而，GNNs探索从非结构化数据(如场景图片和故事文档)生成图形，这可以为进一步的高级AI提供强大的神经模型。近年来，gnn在文本分类[2]、[25]、神经机翻译[4]、[7]、关系提取[63]、[69]、图像分类[28]等方面得到了广泛的应用[99]。

目前对图神经网络的研究有较全面的综述。[80]给出了早期图神经网络方法的形式化定义。和[79]展示了图神经网络的近似性质和计算能力。[64]提出了一个统一的框架，MoNet，将CNN架构推广到非欧几里得域(图和流形)，该框架可以推广图[2]、[46]上的几种光谱方法，以及流形[10]上的一些模型，[61]。[11]对几何深度学习进行了全面的回顾，提出了几何深度学习存在的问题、难点和解决方法,用途及未来发展方向。[64]，[11]侧重于将卷积推广到图形或流形，但本文只关注图形上定义的问题，还研究了图形神经网络中使用的其他机制，如门机制、注意机制和跳跃连接。[30]提出的消息传递神经网络(MPNN)可以推广几种图神经网络和图卷积网络方法。给出了信息传递神经网络的定义，并演示了其在量子化学中的应用。[98]提出了非局部神经网络(non-local neural network, NLNN)，它统一了几种自我关注的方式。然而，该模型并没有在原始论文的图表上明确定义。针对具体的应用领域，[30]和[98]只给出了如何使用其框架泛化其他模型的例子，并没有对其他的图神经网络模型进行综述。[6]提出了图形网络(GN)框架。该框架具有较强的推广其他模型的能力，其关系归纳偏差促进了组合推广，这被认为是人工智能的重中之重。但是，[6]是部分意见书，部分综述，部分统一，仅对应用进行了粗略分类。本文对不同的图神经网络模型进行了全面的综述，并对其应用进行了系统的分类。

综上所述，本文对图神经网络进行了广泛的研究，贡献如下。

- 我们对现有的图神经网络模型进行了详细的回顾。我们介绍了原始的模型、它的变体和一些通用框架。我们研究了这一领域的各种模型，并提供了一个统一的表示来表示不同模型中的不同传播步骤。通过识别相应的聚合器和更新器，可以很容易地使用我们的表示来区分不同的模型。
- 我们系统地对应用程序进行分类，并将应用程序划分为结构化场景、非结构化场景和其他场景。我们介绍了几种主要的应用程序及其在不同场景中的相应方法。
- 我们提出了四个有待进一步研究的问题。图神经网络存在过度平滑和缩放问题。目前还没有有效的方法来处理动态图形和建模非结构化的感觉数据。我们对每个问题进行了深入的分析，并提出了未来的研究方向。

本调查的其余部分组织如下。在第2节中，我们介绍了图神经网络族中的各种模型。首先介绍了原始框架及其局限性。然后我们提出了它的变体，试图释放这些限制。最后介绍了近年来提出的几种通用框架。在第3节，我们将介绍图神经网络在结构场景、非结构场景和其他场景中的几个主要应用。在第4节中，我们提出了图神经网络的四个开放问题以及未来的几个研究方向。最后，我们在第五节中总结了调查结果。

## 2 模型

图神经网络是非欧几里得结构上有用的工具，文献中提出了各种方法来改进模型的性能。

在2.1节中，我们描述了[80]中提出的原始图神经网络。我们还列出了原始GNN在表示能力和训练效率方面的局限性。在2.2节中，我们介绍了几种不同的图神经网络，旨在释放这些限制。这些变体操作不同类型的图形，利用不同的传播函数和先进的训练方法。在2.3节中，我们提出了三个通用框架，它们可以概括和扩展几个工作线。其中，消息传递神经网络(MPNN)[30]融合了各种图神经网络和图卷积网络方法;非局部神经网络(NLNN)[98]结合了几种自我注意类型的方法。而图神经网络(GN)[6]可以泛化本文提到的几乎所有的图神经网络变体。

在进一步进入不同的部分之前，我们给出了将在整篇论文中使用的标记。表示法的详细描述见表1。

### 2.1图神经网络

图神经网络(GNN)的概念最早是在[80]中提出的，它扩展了现有的神经网络来处理图域中表示的数据。在图中，每个节点都是由其特征和相关节点自然定义的。GNN的目标是学习一种包含每个节点邻域信息的状态嵌入hv R s。状态嵌入hv是节点v的一个s维向量，可用于产生节点标签等输出ov。设f为参数函数，称为局部转移函数，在所有节点间共享，并根据输入邻域更新节点状态。设g为描述输出如何产生的本地输出函数。然后，hv和ov的定义如下

![1545705913918](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545705913918.png)

其中xv、xco[v]、hne[v]、xne[v]分别是v的特征、v的边缘特征、状态特征和v邻域节点的特征。

令H、O、X、XN为分别叠加所有状态、所有输出、所有特征和所有节点特征构成的向量。然后我们有一个紧凑的形式为:![1545706217578](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545706217578.png)

其中，全局转换函数F和全局输出函数G分别是图中所有节点的F和G的堆叠版本。H的值是Eq. 3的不动点，且唯一的定义是假设F是一个收缩映射。

在巴拿赫不动点定理[44]的建议下，GNN采用以下经典迭代方法计算状态。

![1545706460457](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545706460457.png)

式中，Ht为H的第t次迭代，对于任意初值H(0)，动力系统Eq. 5指数收敛速度快于Eq. 3的解。注意，f和g中描述的计算可以解释为前馈神经网络。

当我们有了GNN的框架后，下一个问题是如何学习f和g的参数。以目标信息(某一特定节点的tv)作为监督，损失可以写成![1545706516539](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545706516539.png)

其中p是被监督的节点数。该学习算法基于梯度下降策略，由以下步骤组成。

- 状态$h^t_v$由Eq. 1迭代更新直到时刻t，它们接近公式3的不动点解:$h (t) \approx h $
- 权值W的梯度是由损失计算出来的。
- 权值W根据上一步计算的梯度进行更新。

**局限**：虽然实验结果表明，GNN是一种功能强大的结构化数据建模体系结构，但是原有的GNN仍然存在一些局限性。首先，对于不动点迭代更新节点的隐藏状态是低效的。如果放松不动点的假设，可以设计一个多层的GNN来得到节点及其邻域的稳定表示。其次，GNN在迭代中使用相同的参数，而大多数神经网络在不同的层中使用不同的参数，这是一种分层特征提取方法。此外，节点隐藏状态的更新是一个连续的过程，可以从像GRU和LSTM这样的RNN内核中获益。第三，边缘也有一些原始GNN无法模拟的信息特征。例如，知识图中的边具有关系的类型，不同边之间的消息传播应该根据它们的类型而有所不同。此外，如何学习边缘的隐藏状态也是一个重要的问题。最后，如果我们把焦点放在节点的表示上而不是图形上，就不适合使用不动点，因为在不动点上的表示的分布在数值上很平滑，区分每个节点的信息量也比较小。

![1545707142147](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545707142147.png)

### 2.2 图神经网络的变体

在这个小节中，我们提出了图神经网络的几种变体。第2.2.1节关注在不同图形类型上操作的变体。这些变体扩展了原始模型的表示能力。第2.2.2节列出了传播步骤上的几个修改(卷积、门机制、注意机制和跳过连接)，这些模型可以更好地学习表示。第2.2.3节介绍了使用高级培训方法的变体，提高了培训效率。图2概括了图神经网络的不同变体。

#### 2.2.1图类型

有向图图的第一个变体是有向图。无向边可以看作是两个有向边，说明了两个节点之间的关系。然而，有向边比无向边能带来更多的信息。例如，在一个知识图中，边从head实体开始到tail实体结束，head实体是tail实体的父类，这就意味着我们应该区别对待父类和子类的信息传播过程。ADGPM[41]采用Wp和Wc两种权重矩阵，结合更精确的结构信息。传播规律如下:

![1545707768534](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545707768534.png)

其中d1pap、d1cac分别为父节点和子节点的归一化邻接矩阵。

异构图图的第二种变体是异构图，其中有几种节点。处理异构图的最简单方法是将每个节点的类型转换为与原始特征连接的一个热门特征向量。此外，GraphInception[111]在异构图的传播中引入了元路径的概念。使用metapath，我们可以根据邻居的节点类型和距离对其进行分组。对于每个相邻组，GraphInception将其作为同构图中的子图来进行传播，并将来自不同同构图的传播结果连接起来，以进行集合节点表示。

边缘信息图：在图形的最后一种变体中，每条边都有自己的信息，比如边的权值或者边的类型。有两种方法来处理这类图:首先,我们可以将图转换成两偶图原边也成为节点和一个原边分成两个新的边缘这意味着有两个边缘之间的边缘节点和开始/结束节点。编码器的g2[7]使用下面的邻居的聚合函数:![1545707995802](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545707995802.png)

其中Wr和br为不同类型边(关系)的传播参数。其次，我们可以采用不同的权矩阵在不同的边缘上进行传播。当关系数量很大时，r-GCN[81]引入两种正则化方法来减少关系数量建模的参数数量:基-和块-对角线-分解。根据基分解，每个Wr定义如下:

![1545708170446](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545708170446.png)

即，R - gcn是Vb R din dout与系数arb的基变换的线性组合，使得系数仅依赖于R。在块对角分解中，R - gcn通过对一组低维矩阵的直接和来定义每个Wr，这些低维矩阵比第一个低维矩阵需要更多的参数。

#### 2.2.2 传播类型

传播步骤和输出步骤对于获取节点(或边)的隐藏状态至关重要。如下表所示，在传播步骤中，原图神经网络模型有几个主要的修改，而研究人员通常在输出步骤中遵循一个简单的前馈神经网络设置。GNN的不同变体比较见表2。这些变体使用不同的聚合器从每个节点的邻居和特定的更新器收集信息，以更新节点的隐藏状态。

卷积:将卷积推广到图域的兴趣越来越大。这方面的进展通常分为光谱方法和非光谱方法。

谱方法是用图的谱表示来工作的。[12]提出了光谱网络。通过计算图像拉普拉斯变换的特征分解，在傅立叶域中定义了卷积运算。操作可以被定义为一个信号的乘法x R N为每个节点(标量)和一个过滤器gθ=诊断接头(θ)参数化θ ∈ RN:

![1545708380116](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545708380116.png)

U是矩阵的特征向量归一化图像的拉普拉斯算子L = D公元1 2 1 2 = UΛUT(D度矩阵和图的邻接矩阵),一个对角矩阵的特征值Λ。

这种操作会导致潜在的密集计算和非空间局部化过滤器。[38]试图通过引入具有平滑系数的参数化，使谱滤波器空间局域化。[34]表明gθ(Λ)可以用一个截断近似扩张的切比雪夫多项式Tk k阶(x)。因此，操作是：

![1545720042712](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545720042712.png)

L˜=2λmax L−in.λmax表示L的最大特征值，θ∈R，K现在是θ∈系数的向量。Chebyshev多项式定义为Tk(X)=2xTk−1(X)−tk−2(X)，其中T0(X) =1和T1(X)=x。在Laplacian中，由于它是一个KTH阶多项式，所以它是K-局部化的。[25]利用这个k-局部卷积定义了一个卷积神经网络。 可以消除计算拉普拉斯特征向量的需要的工作。

[46]将分层卷积运算限制为K = 1，以减轻对于节点度分布非常宽的图的局部邻域结构的过拟合问题。它进一步接近λmax 2和方程简化为:

![1545720491991](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545720491991.png)

有两个自由参数θ0 0和θ0 1。在用θ=θ0 0=−θ0 1约束参数之后，我们可以获得以下表达式：

![1545720536163](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545720536163.png)

注意，叠加这个算子可能会导致数值不稳定和梯度爆炸/消失，[46]引入了重整化技巧:在+ d12 ad12 d12 a12, A = A + IN和D ii = pja ij。最后，[46]将该定义推广到信号xrnc，特征映射采用C输入通道和F滤波器，如下所示:

![1545720970323](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545720970323.png)

ΘR C F是一个矩阵滤波器的参数和Z N R F是卷积信号矩阵。

然而，在上述所有光谱方法中，学习滤波器依赖于拉普拉斯特征基，而拉普拉斯特征基依赖于图的结构，即基于特定结构训练的模型不能直接应用于具有不同结构的图。

非谱方法直接在图上定义卷积，操作空间上的近邻。非谱方法的主要挑战是定义具有不同大小邻域的卷积运算和保持CNNs的局部方差。

对于不同程度的节点，[26]使用不同的权重矩阵:

![1545721085634](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545721085634.png)

其中WNv L为第L层Nv度节点的权值矩阵，该方法的主要缺点是不能应用于节点度较大的大规模图。

[2]提出了扩散卷积神经网络(DCNNs)。转换矩阵用于定义DCNN中节点的邻域。对于节点分类，它有:

![1545721234306](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545721234306.png)

其中X是输入特征的N×F张量(N是节点数，F是特征数)。P∗是一个N×K×N张量，它包含矩阵P的幂级数{P，P2，…，PK}，P是 图邻接矩阵A中的度归一化转移矩阵A，将每个实体转化为扩散卷积表示，即由图di的K阶跃点定义的K×F矩阵。 F特征的模糊。然后用一个K×F权矩阵和一个非线性激活函数f来定义它。最后，H(N×K×F)表示每个节点的扩散表示。 在图中。

在图分类方面，DCNN只取节点表示的平均值

![1545721278741](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545721278741.png)

这里是一个由1组成的向量。DCNN也可以应用于边缘分类任务，这需要将边缘转换为节点，并增加邻接矩阵。

[66]提取每个节点恰好k个节点的邻域，并将其标准化。然后归一化邻域作为卷积运算的接受域。

[64]提出了一种基于非欧几里得域的空间域模型(MoNet)，该模型可以推广之前的几种技术。流形上的测地线CNN (GCNN)[61]和各向异性CNN (ACNN)[10]或图形上的GCN[46]和DCNN[2]可以表示为莫奈的特殊实例。

[33]提出了GraphSAGE，一个通用的归纳框架。该框架通过对节点的局部邻域特征进行采样和聚合来生成嵌入。![1545722148836](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545722148836.png)

然而，[33]并没有使用Eq.18中的完整的邻居集，而是通过均匀采样的固定大小的邻居集。[33]提出了三个聚合函数。

- 平均聚集器。平均聚合器简单地将邻居隐藏状态的元素平均化。它可以看作是从换能器GC的8卷积运算的近似。 n框架[46]，以便GCN变体的归纳版本可由![1545722229267](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545722229267.png)平均聚合器不同于其他聚合器，因为它不执行连接h t1 v和h tnv的连接操作。连接操作可以是视图，作为跳过连接[37]的一种形式，可以提高性能。
- LSTM聚合器。[33]还使用了一个基于lsm的聚合器，它具有更大的表达能力。然而，LSTMs以顺序的方式处理输入，因此它们不是排列不变的。[33]使LSTMs通过置换节点的邻居来对无序集进行操作。
- 池聚合器。在池聚集器中，每个邻居的隐藏状态通过一个完全连接的层进行馈送，然后将最大池操作应用于节点的邻居集。![1545722573445](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545722573445.png)请注意，这里可以使用任何对称函数来代替最大池操作。

门。有几项工作尝试在传播步骤中使用gate机制，如GRU[19]或LSTM[39]，以减少前GNN模型的限制，改善信息在图形结构中的长期传播。

[53]提出了门控图神经网络(GGNN)，该神经网络在传播步骤中使用了门控递归单元(GRU)，对一定数量的步骤T展开递归，并通过时间反向传播来计算梯度。

具体来说，传播模型的基本递归是![1545725673010](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545725673010.png)

节点v首先聚合来自相邻节点的消息，其中Av为图邻接矩阵A的子矩阵，表示节点v与其相邻节点的连接。类似于grub的更新函数包含来自其他节点和上一个时间步骤的信息，以更新每个节点的隐藏状态。a采集节点v的邻域信息，z和r为更新和复位门。

LSTMs在基于树或图的传播过程中也以类似于GRU的方式使用。

[88]对LSTM基本架构提出了两个扩展:子和树LSTM和n元树LSTM。与标准LSTM单元一样，每个树型LSTM单元(以v为索引)包含输入和输出门iv和ov、一个存储单元cv和隐藏状态hv。树- lstm单元为每个子k包含一个忘记门fvk，而不是单个忘记门，允许单元选择性地合并来自每个子k的信息。子和树lstm转换方程如下:

![1545789449598](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545789449598.png)

在标准的LSTM设置中，xtv是时间t的输入向量。

如果树的分支系数不超过K，且节点的所有子节点都是有序的，即，它们可以从1到K进行索引，然后使用N-ary Tree-LSTM。对于节点v, h t vk和ct vk分别表示其第k个子节点在t时刻的隐藏状态和内存单元。过渡方程如下:

![1545789511186](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545789511186.png)

为每一个子k引入单独的参数矩阵，允许模型学习更多的细粒度表示，这些表示条件是基于单元s子节点的状态，而不是子和树lstm。

两种类型的树lstms可以很容易地适应图形。[108]中的图形结构LSTM是应用于图形的n元树LSTM的一个例子。但是，这是一个简化版本，因为图中的每个节点最多有2条传入边(来自其父节点和兄弟节点)。[69]提出了基于关系提取任务的图LSTM的另一种变体。图和树之间的主要区别是图的边有它们的标签。和[69]利用不同的权重矩阵表示不同的标签。

![1545789584562](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545789584562.png)

其中m(v, k)表示节点v与k之间的边标签.

[109]提出了用于改进文本编码的句子LSTM (S-LSTM)。它将文本转换为图形，并利用图形LSTM来学习表示。在许多NLP问题中，S-LSTM具有很强的表示能力。[56]提出了一个图形LSTM网络来处理语义对象解析任务。该算法采用可信驱动的方案自适应选择起始节点，确定节点更新序列。它遵循将现有的LSTMs一般化到图形结构化数据中的相同思想，但是具有特定的更新序列，而我们上面提到的方法与节点的顺序无关。

注意力机制:注意机制已成功地应用在许多基于序列任务,如机器翻译[3],[29],[93],机读[18]等等。[94]提出了一种图形注意网络(graph attention network, GAT)，将注意机制融入到传播步骤中。它根据自我关注策略，通过关注相邻节点来计算每个节点的隐藏状态。

[94]提出了单图注意层，并通过叠加这一层构造了任意图的注意网络。该层计算节点对注意机制中的系数(I)。 (J)通过：

![1545789678595](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545789678595.png)

其中αij是节点j对i的注意系数，Ni表示图中节点i的邻域。该层的节点特征输入集为h={h1，h2，。。。，Hn}，嗨，∈R，F，Whe Re N是节点的数目，F是每个节点的特征数，该层生成一组新的节点特征集(具有潜在不同基数的F0)，h0={h0 1，h0 2，。。。，H0 N }，h0 i∈RF0，作为它的输出。W∈rf 0×F是适用于每个节点的共享线性变换的权矩阵，∈r2f0是单层前馈神经网络的权向量。 网络。它由一个软最大值函数归一化，并应用LeakyReLU非线性(负输入斜率α=0.2)。

然后每个节点的最终输出特性可以通过(在应用非线性σ)：

![1545789732158](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545789732158.png)

此外，该层利用与[93]类似的多头注意来稳定学习过程。它适用于K独立的注意机制计算隐状态然后连接他们的特性(或计算平均),导致以下两个输出表示:![1545789963874](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545789963874.png)

在αk ij是规范化注意k系数计算的注意机制。

[94]中的注意结构具有以下几个特点:(1)节点-邻居对的计算是可并行的，因此操作效率高;(2)通过对相邻节点指定任意权值，可以应用于不同程度的图节点;(3)易于应用于归纳学习问题。

跳过连接。许多应用程序展开或堆叠图形神经网络层，以达到更好的效果，作为更多的层(i。e k层)使每个节点从相邻的k个跃点聚合更多的信息。然而，在许多实验中观察到，更深层次的模型并不能提高性能，更深层次的模型甚至可能表现更差的[46]。这主要是因为更多的层还可以从成倍增长的扩展邻居成员中传播噪声信息。

解决这个问题的一种简单的方法，残余网络[36]，可以从计算机视觉社区中找到。但是，即使使用剩余连接，具有更多层的GCNs在许多数据集[46]上的表现也不如2层GCN。

[73]提出了一种类似公路网的采用分层门的公路GCN[112]。一个层的输出和它的输入加上门限权重：

![1545790086001](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545790086001.png)

在[73]中讨论的一个具体问题中，通过增加高速公路闸门，其性能在4层处达到峰值。

[103]研究了邻域聚集方案的性质及其局限性。提出了一种能学习自适应、结构感知表示的跳跃式知识网络。跳跃Kn Oledge Network se？从最后一层的每个节点的所有中间表示(“跳转”到最后一层)，从而使模型适应有效的邻域大小。 每个节点视需要而定。[103]在这10个实验中，使用了级联、最大池和LSTM-注意三种方法来聚合信息。跳跃式知识网络在实践中的应用 社会、生物信息学和引文网络。它还可以与图形卷积网络、图形SAGE和图形注意力网络等模型相结合，以提高它们的性能。

#### 2.2.3 训练方法

原图卷积神经网络在训练和优化方法上存在一些缺陷。具体来说，GCN需要完整的图Laplacian，这对于大型图来说是计算消耗的。此外，节点在L层的嵌入是通过所有相邻节点在L层1的嵌入递归计算的。因此，单个节点的接受域相对于层数呈指数增长，因此计算单个节点的梯度代价很大。最后，对于固定的图，GCN是独立训练的，缺乏归纳学习的能力。

GraphSAGE[33]是对原有GCN的全面改进。为了解决上述问题，GraphSAGE用可学习的聚合函数替换了完整的图Laplacian，这些聚合函数是执行消息传递并推广到不可见节点的关键。如Eq.18所示，它们首先聚合邻域嵌入，连接目标节点嵌入，然后传播到下一层。通过学习聚合和传播函数，GraphSAGE可以为不可见节点生成嵌入。此外，GraphSAGE使用邻居采样来缓解接受域扩展。

FastGCN[15]进一步改进了采样算法。FastGCN不对每个节点的邻居进行采样，而是直接对每个层的接收字段进行采样。FastGCN使用重要性抽样，其中重要因素计算如下：

![1545790349364](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545790349364.png)

[16]利用节点的历史激活作为控制变量，提出了一种基于控制变量的GCN随机逼近算法。该方法限制了1-hop邻近区域的接受域，但使用历史隐藏状态作为可承受的近似。

[52]着重讨论了GCN的局限性，其中包括GCN需要很多额外的带标签数据进行验证，同时也受到卷积滤波器本地化的影响。针对这一局限性，作者提出了协同训练GCN和自我训练GCN来扩展训练数据集。前者寻找训练数据的近邻，后者寻找训练数据的近邻。 恩采用了一种类似于提振的方式。

### 2.3 一般框架

除了图形神经网络的不同变体外，还提出了几种通用框架，旨在将不同的模型集成到一个单一的框架中。[30]提出了消息传递神经网络(MPNN)，将各种图神经网络和图卷积网络方法统一起来。[98]提出了非局部神经网络(NLNN)。它结合了几种自我注意风格的方法[40]，[93]，[94]。[6]提出了图形网络(GN)，它统一了MPNN和NLNN方法以及许多其他变体，如交互网络[5]，[102]，神经物理引擎[14]，CommNet [86]， structure2vec [22]， [23]， GGNN[53]，关系网络[74]，[78]，Deep Sets[107]和Point Net[71]。

#### 2.3.1 消息传递神经网络

[30]提出了一种对图进行有监督学习的通用框架，称为消息传递神经网络(MPNNs)。MPNN框架抽象了几个最流行的 图结构数据的模型，如谱方法[12][25]，[46]和非谱方法[26]，图卷积，门控图神经网络[53]，相互作用网络[5]，分子 Ar图卷积[42]，深张量神经网络[82]等。

该模型包括两个阶段，消息传递阶段和读出阶段。消息传递阶段(即传播步骤)运行于T时间步骤，由消息函数Mt和顶点更新函数Ut定义。使用消息太v,隐状态h t v的更新功能如下:

![1545791551296](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545791551296.png)

其中evw表示节点v到w的边缘特征，读出阶段利用读出函数R计算出整个图形的特征向量。

![1545791641359](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545791641359.png)

其中T为总时间步长。消息函数Mt、顶点更新函数Ut和读出函数R可以有不同的设置。因此，MPNN框架可以通过不同的功能设置来推广几种不同的模型。这里我们给出了一个推广GGNN的例子，其他的模型函数设置可以在[30]中找到。GGNNs的函数设置如下![1545791679168](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545791679168.png)

其中Aevw为邻接矩阵，每个边标e对应一个邻接矩阵。GRU为[19]中引入的门控回归单元。i和j是函数R中的神经网络。

#### 2.3.2 非局部神经网络

[98]提出了非局部神经网络(Non-local Neural Networks, NLNN)来捕获与深度神经网络的长距离依赖关系。非局部运算是经典的计算机视觉非局部平均运算[13]的推广。非本地操作将在一个位置上的响应计算为所有位置上的特征的加权和。位置集可以是空间、时间或时空。因此，NLNN可以看作是不同自我注意风格方法的统一，[40]，[93]，[94]。我们将首先介绍非本地操作的一般定义，然后介绍一些特定的实例。

在非局部均值操作[13]之后，一般的非局部操作定义为：

![1545791781084](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545791781084.png)

其中i是输出位置的索引，j是列出所有可能位置的索引。f(hi, hj)计算i和j之间的标量，表示它们之间的关系。g(hj)为输入hj的变换，利用因子1 C(h)对结果进行归一化。

有几个实例具有不同的f和g设置。为简便起见，[98]将线性变换作为函数g，即g(hj) = Wghj，其中Wg是一个学习权矩阵。下面我们列出函数f的选项。

高斯函数。Guassian函数是非局部均值[13]和双边滤波器的自然选择[91]。因此

![1545791857887](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545791857887.png)

这里hj是点积相似性，C(h) = jf (hi, hj)。

嵌入式高斯。通过计算嵌入空间中的相似度，可以直接对高斯函数进行扩展：![1545806790126](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545806790126.png)

其中θ(Hi)=Wθhi P，φ(Hj)=Wφhj，C(H)=∀j f(hi，hj)。

可以发现，文[93]中提出的自我注意是嵌入式高斯版本的一个特例。对于给定的i，1C(H)f(hi，hj)成为维数j上的Softmax计算。 因此，h0=Softmax(h tWTθWφh)g(H)，与[93]中的自我注意形式相匹配。

点积。函数f也可以实现为点积相似性：![1545806851453](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545806851453.png)

这里因子C(h) = N，其中N是h中的位置数。

连接。这里我们有![1545806938703](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545806938703.png)

其中wf是一个权向量，它将向量投影到标量上，C(h) = N。

[98]将上述非本地操作包装为非本地块：![1545806982938](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545806982938.png)

其中h0 i在Eq.34中给出，+hi表示剩余连接[36]。因此，可以将非局部块插入到任何预先训练的模型中，从而使该块更加适用。

2.3.3 图网络

[6]提出了图网络(GN)框架，该框架推广和扩展了各种图神经网络，MPNN和NLNN方法[30]、[80]、[98]。我们首先介绍了[6]和 然后描述了核心GN计算单元GN块及其计算步骤，最后介绍了GN块的基本设计原理。

图的定义。在[6]中，图形被定义为一个三元组G = (u, H, E)(这里我们用H代替V来表示一致性)。u是一个全局属性，H = {hi}i=1:Nv是节点集(基数Nv)，其中每个hi是节点s属性。E = {(ek, rk, sk)}k=1:Ne是边的集合(cardinality Ne)，其中每个ek都是edges属性，rk是接收者节点的索引，sk是发送者节点的索引。

GN块。GN块包含三个“更新”函数(φ)和三个“聚合”函数(ρ)，

![1545807152142](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545807152142.png)

其中E0i={(e0k，rk，SK)}rk=i，k=1：ne，h0={h0i}i=1：nv，e0=sie0i={(e0k，rk，sk)}k=1：ne。ρ函数必须对其输入的排列不变量，并且应该采用va。 Riable数的论点。

计算步骤   GN块的计算步骤如下：

1. φe适用于每条边，带有参数(ek，HRK，HSK，u)，并返回e0k。每个节点i的每边输出集为：e0i={(e0k，rk，sk)}rk=i，k=1：ne.E0=Si E0I= {(e0k，rk，sk)}k=1：ne是所有每边输出的集合。
2. ρe→h应用于E0 i，并将该项目的边缘更新聚合到顶点i中，并将其用于下一步的节点更新。
3. φh应用于每个节点i，以计算更新的节点属性h0i。生成的每个节点输出的集合是，H0={h0i}i=1：nv.
4. ρe→u被应用于E0，并将所有边缘更新聚合到e0中，然后在下一步的全局更新中使用。
5. ρh→u被应用于H0，并将所有节点更新聚合到h_→0中，然后在下一步的全局更新中使用。
6. 每个图应用一次φu，并计算全局属性u 0的更新。

注意这里的命令没有严格执行。例如，可以从全局更新到每个节点更新，再到peredge更新。φ和ρ功能不需要神经网络虽然在本文中,我们只关注神经网络实现。

设计原则。图网络的设计基于三个基本原则：灵活的表示、可配置的块内结构和可组合的多块结构。

- 灵活的表示。GN框架支持属性的灵活表示以及不同的图形结构。在属性方面，全局属性、节点属性和边缘属性可以使用任意的表示格式，例如序列、集合甚至图形。但是实值向量和张量是最常见的。GN s输出的矢量/张量表示也允许将输出传递给其他深度学习块，如MLPs、CNNs或RNNs。可以根据任务的具体需求，对GN块的输出进行简单的调整。例如，[6]列出了几个边缘聚焦的[35]、[45]、节点聚焦的[5]、[14]、[77]、[97]和图形聚焦的[5]、[30]、[78]GNs。就图结构而言，框架既可以应用于图结构明确的结构场景，也可以应用于关系结构推断或假设的非结构场景。
- 可配置within-block结构。GN块中的函数及其输入可以有不同的设置，这样GN框架就可以在块内结构配置中提供灵活性。例如，[35]和[77]使用完整的GN块。φ实现使用神经网络和ρ函数使用elementwise求和。基于不同的结构和功能设置，GN框架可以表达多种模型(如MPNN、NLNN等)。更多细节可以在[6]中找到。
- 可组合的多块体系结构。GN块可以用来构造复杂的体系结构。任意数目的GN块可以用共享或未共享的参数按顺序组成。 [6]利用GN块构造一个编码过程解码结构和一个基于递归GN的体系结构。这些体系结构如图3所示。其他基于GN的AR构建技术 架构也可能是有用的，例如跳过连接、LSTM-或GRU式的门控方案等等。

## 3.应用

图神经网络已经在广泛的问题领域中得到了探索，这些领域包括有监督、半监督、无监督和强化学习设置。在本节中，我们简单地将应用程序划分为三个场景:(1)数据具有显式关系结构的结构化场景，如物理系统、分子结构和知识图;(2)关系结构不明确的非结阿构化场景包括图像、文本等;(3)生成模型、组合优化问题等其他应用场景。注意，我们只列出了几个有代表性的应用程序，而没有提供详尽的列表。应用程序摘要见表3。

### 3.1 结构的场景

在下面的小节中，我们将介绍GNN s在结构场景中的应用程序，在这些场景中，数据自然地以图形结构执行。例如，GNNs广泛应用于社交网络预测[33]、[46]、流量预测[21]等[73]和推荐系统[92]、[105]。具体地说，我们讨论了如何用对象关系图对现实世界的物理系统建模，如何预测分子的化学性质和蛋白质的生物相互作用性质，以及知识图中自知识库实体的推理方法。

#### 3.1.1 物理

模拟真实世界的物理系统是理解人类智能最基本的方面之一。通过将对象表示为节点，将关系表示为边，我们可以以一种简单而有效的方式对对象、关系和物理进行基于gnn的推理

[5]提出了相互作用网络，对各种物理系统进行预测和推断。该模型以对象和关系为输入，它们相互作用的原因，并应用 影响和物理动力学预测新的状态。它们分别对以关系为中心的模型和以对象为中心的模型进行建模，从而使跨不同系统的泛化变得更加容易。

视觉交互网络[102]可以从像素进行预测。它从每个对象的两个连续输入帧中学习一个状态代码。然后，在将它们的相互作用加到一个Intera之后 NET块，状态译码器将状态码转换为下一步的状态。

[77]提出了一种基于图网络的模型，既可以进行状态预测，也可以进行归纳推理。推理模型以部分观察到的信息作为输入，并构造一个隐藏信息。 隐式系统分类图。

#### 3.1.2 化学和生物学

分子指纹计算是计算机辅助药物设计中的一个核心步骤，它是表征分子特征向量的特征向量。传统的分子指纹图谱是 手工制作的和固定的。通过在分子图上应用GNN，可以获得更好的指纹图谱。

![1545808830640](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545808830640.png)

[26]提出的神经图指纹通过GCN和SUM计算子结构特征向量，得到整体表示。聚合函数是

![1545808869325](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545808869325.png)

其中EUV是边(u，v)的边缘特征。然后通过以下方式更新节点表示：

![1545808901324](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545808901324.png)

其中deg(V)是节点v的度，WNt是每个时间步长t和节点度N的学习矩阵。

[42]进一步明确地独立地模拟原子和原子对，以强调原子之间的相互作用。它引入边表示e t uv而不是聚集函数，即htnv=pu∈n(V)etu。 五.节点更新功能是

![1545808936330](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545808936330.png)

而边缘更新函数是

![1545809128861](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545809128861.png)

![1545809152477](F:\Machine-learning-and-data-science-notebook\images\图神经网络：应用和技术回顾\%5CUsers%5CDELL%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1545809152477.png)

**蛋白质界面预测 **  [27]集中在蛋白质界面预测这一课题上，它在药物发现和设计中具有重要的应用价值。提议的全球氯化萘 ED法分别学习配体和受体蛋白残基的表达，并将它们合并为成对分类。

GNN也可以用于生物医学工程。利用蛋白-蛋白相互作用网络[75]，利用图卷积和关系网络对乳腺癌亚型进行分类。[113]还提出了一种基于GCN的多药副作用预测模型。他们的工作模拟了药物和蛋白质的相互作用网络，并分别处理不同类型的边缘。

#### 3.1.3 知识图谱

[32]利用GNN解决知识库完成(KBC)中的OOKB实体问题。知识库外实体是在培训Tim时没有观察到的测试实体。 e.[32]中的OOKB实体直接连接到现有实体，因此OOKB实体的嵌入可以从现有实体中聚合。文[32]中提出的方法实现了卫星通信。 在标准KBC设置和OOKB设置中都要考虑性能。

### 3.2 非结构性的场景

在本节中，我们将讨论非结构化场景中的应用程序，如图像、文本、编程源代码[1]、[53]和多代理系统[40]、[45]等[86]。由于篇幅的限制，我们只对前两种场景进行详细的介绍。将图神经网络应用于非结构化场景大致有两种方式:(1)结合其他领域的结构信息来提高性能，例如利用知识图的信息来缓解图像任务中的零拍问题;(2)推断或假设场景中的关系结构，然后应用模型解决图上定义的问题，如[109]中将文本建模为图的方法。

#### 3.2.1 图像

**图像分类**：图像分类是计算机视觉领域的一项非常基础和重要的工作，它受到了人们的广泛关注，并拥有许多著名的数据集，如ImageNet[76]。图像分类的最新进展得益于大数据和强大的GPU计算能力，这使得我们可以在不从图像中提取结构信息的情况下训练分类器。然而，在图像分类领域，零拍和少拍学习越来越受欢迎，因为大多数模型都可以在足够的数据下达到相似的性能。有几项工作利用图形神经网络合并结构信息在图像分类。首先，知识图可以作为额外信息来指导零短时间识别分类[41]，[99]。[99]构建一个知识图，其中每个节点对应一个对象类别，并以节点嵌入词作为输入，预测不同类别的分类器。由于卷积架构的深度会产生过平滑效应，[99]中使用的6层GCN会在表示中洗去很多有用的信息。为了解决GCN传播中的平滑问题，[41]采用了具有较大邻域的单层GCN，该邻域包括图中的单跳和多跳节点。并证明了该方法在现有零炮点分类器基础上的有效性。

除了知识图谱外，数据集中图像之间的相似度也有助于减少学习[28]的次数。[28]提出了一种基于相似度的加权全连通图像网络，并在图中进行消息传递，实现小镜头识别。由于大部分知识图推理量较大，[60]根据对象检测结果选取相关实体构建子图，并将GGNN应用于提取的图中进行预测。此外，[51]提出构建一个新的知识图，其中实体为所有类别。他们定义了三种类型的标签关系:超从属关系、正相关关系和负相关关系，并直接在图中传播标签的可信度。

**视觉推理**:计算机视觉系统通常需要进行推理,通过融合空间和语义信息。因此，生成用于推理任务的图形是很自然的。一个典型的视觉推理任务是视觉问答(visual question answer, VQA)，[90]分别构建图像场景图和问题句法图。然后运用GGNN对嵌入和注意机制进行训练，预测最终答案。[101]进一步利用知识图进行更精细的关系探究。视觉推理的另一个应用是建立区域识别系统。普通CNN只能捕捉局部空间特征，缺乏语义和全局推理能力。[17]提出了基于图形的推理模块，该模块连接区域和类。在本工作中，GCN用于消息传递。

一个典型的视觉推理任务是视觉问答(visual question answer, VQA)，[90]分别构建图像场景图和问题句法图。然后运用GGNN训练嵌入和注意机制来预测最终答案。[101]进一步利用知识图进行更精细的关系探究。

视觉推理的另一个应用是建立区域识别系统。普通CNN只能捕捉局部空间特征，缺乏语义和全局推理能力。[17]提出了基于图形的推理模块，该模块连接区域和类。在这个工作中，GCN用于消息传递。

**语义分割**:语义分割是图像理解的重要一步。这里的任务是为图像中的每一个像素分配一个唯一的标签(或类别)，这可以看作是一个密集的分类问题。然而，图像中的区域往往不是网格状的，需要非局部的信息，这导致了传统CNN的失败。一些工作使用图形结构化数据来处理它。

[56]提出了一种基于距离的超像素图的图形LSTM模型，该模型通过构建基于距离的超像素图的形式，将邻域信息进行全局传播，从而对长期依赖关系和空间连接关系进行建模。后续工作从编码层次信息[55]的角度对其进行了改进。

此外，三维语义分割(RGBD语义分割)和点云分类利用了更多的几何信息，因此很难用二维CNN进行建模。[72]构建K近邻图(K nearest neighbour, KNN)，使用3D GNN作为传播模型。在展开多个步骤后，预测模型将每个节点的隐藏状态作为输入，预测其语义标签。

由于点总是太多，[48]通过构建超点图并生成嵌入来解决大规模三维点云分割问题。为了对超节点进行分类，[48]利用了GGNN和图卷积。

[100]提出了基于边缘的点交互建模方法。它们通过输入其终端节点的坐标来计算边缘表示向量。然后通过边缘聚合更新节点嵌入。

#### 3.2.2 文本

图神经网络可以应用于多种基于文本的任务。它可以应用于两个句子级的任务(例如:文本分类)以及单词级别的任务(例如。序列标签)。下面我们将介绍几个主要的文本应用程序。

**文本分类：**文本分类是自然语言处理中的一个重要而经典的问题。经典 GCN模型[2]、[25]、[33]、[38]、[46]、[64]和GAT模型[94]都是适用的。 为了解决这个问题，他们只使用文档之间的结构信息，而不使用大量的文本信息。[68]提出了一种基于cnn的深度学习模型，该模型首先将文本转换为文字图，然后利用[66]中的图卷积运算16将单词图进行转换。[[109]提出用句子LSTM对文本进行编码。它将整个句子视为一个单一的状态，由单个单词的子状态和整个句子的层次状态组成。它使用全局语句级表示来分类任务。这些方法要么将文档或句子视为字节点图，要么依赖文档引用关系来构造图。[104]将文件和文字视为节点 UCT的语料库图(因此异构图)，并使用文本GCN学习嵌入的文字和文档。情感分类也可以看作是一个文本分类问题。 文[88]提出了一种树-LSTM方法.

**序列标记：**序列标记由于GNNs中的每个节点都有其隐藏状态，如果将句子中的每个单词都看作一个节点，就可以利用隐藏状态来解决序列标记问题。[109]利用句子LSTM对序列进行标注。在po -tagging和NER task上进行了实验，取得了最先进的性能。

语义角色标记是序列标记的另一项任务。[59]提出了一个句法GCN来解决这个问题。在带标记边的直接图上操作的语法GCN是GCN[46]的一个特殊变体。它集成了边向门，允许模型调节独立依赖边的贡献。句法依赖树上的句法GCNs被用作句子编码器来学习句子中单词的潜在特征表示。[59]还揭示了GCNs和LSTMs在任务中的功能互补。