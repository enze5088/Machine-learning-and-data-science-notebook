# 别走，跳过！多尺度网络嵌入的在线学习

**摘要**-我们提出了一种学习网络中顶点多尺度表示的新方法-WALKLETS。与以前的工作不同，这些表示显式地编码了多尺度的vert。 以一种可分析的可衍生的方式表示的关系。

WALKLETS通过对图的顶点上的短随机游动进行次采样来生成这些多尺度关系。通过在每个随机游动中跳过步骤，我们的方法生成一个顶点p的语料库。 可以通过固定长度的路径到达的AIR。然后，可以使用这个语料库来学习一系列潜在的表示，每个表示都从 邻接矩阵。

我们展示了WALKLETS在BlogCatalog、DBLP、Flickr和YouTube等社交网络多标签网络分类任务上的潜在表示的有效性。我们的结果 现在，WALKLETS优于基于神经矩阵分解的新方法。具体来说，在挑战多标签分类任务方面，我们的表现比DeepWalk高出10%，而排在58%的Micro-F1之上。 s。最后，WALKLETS是一种在线算法，可以很容易地缩放到具有数百万个顶点和边的图。

## 1.介绍

社交网络本质上是分层的。例如，在人类社会网络中，每个人都是几个社区的成员，从小社区(如家庭、朋友)到中等社区(E)。 g。学校，企业)，大到大(例如，民族国家，或所有共同语言的人)。

随着这些关系的规模发生变化，它们的拓扑结构也会发生变化。例如，考虑社交网络上的大学生(如图1a所示)。它们可能与 他们的朋友和直系亲属，并与这些人形成密集的图表结构（例如，接近集团）。但是他们会更宽松地与他们大学的普通学生联系在一起 他们与大多数同学没有直接的社会联系。最后，他们将与他们国家的所有个人有相对较少的联系，但仍将与许多阿特里人有共同之处。 由于共同的文化。规模在预测任务中也起着重要的作用，因为它们也从特定的(例如用户的电影兴趣)到与更多g相关的属性的不同。 一般社区-用户是(例如过去的雇主或学校)的成员。

以前大多数关于网络表示学习的工作都是用“一刀切”的方法来处理的，其中单个网络表示用于为单个用户所做的所有预测。 我们未能显式地捕获节点在网络中的多个关系规模。在我们看来，我们希望有一个系列的表示，它包含了所有的范围。 个人的社区成员。

在本文中，我们研究了将大图中的节点嵌入到有限维d∈RD中的问题，它捕获了节点参与的社区的潜在层次结构。 。这些潜在的多尺度表示对于社会网络中的预测学习任务是有用的。在预测时，可以利用表示(无论是单独的还是组合的)来进行prov。 IDE是一个更全面的用户关联模型。图1b和图1c说明了不同表示尺度上的相似性(潜伏空间中的距离)之间的差异。

最近，人们对社会网络的表征学习产生了浓厚的兴趣，主要是基于神经矩阵分解[1]-[3]。这些方法在半监督网络分类问题上表现出了较强的任务性能。

尽管它们具有强大的任务性能，但我们发现这些方法留下了很大的希望。首先，最初的工作只是间接地解决了多尺度下的学习表示问题。 作为学习过程的产物[1]或通过不同目标函数的不直观组合[2]。最近，一种学习多尺度表示法的方法[3] N提出了，但是它的计算复杂性使得它对大多数现实世界图来说是难以解决的。其次，这些方法大多依赖于“一刀切”的网络表示学习方法， 它掩盖了图表中每个尺度上的细微信息。我们提出了WALKLETS，一种用于学习社会表征的在线算法，它捕获多尺度的关系。 图中顶点之间的电离。与现有工作不同，WALKLETS的维度有意义，允许对捕获的关系进行知情的网络分类和可视化。该方法本身是可扩展的，并且可以在具有数百万个顶点的图上运行。

具体来说，我们的贡献如下：

1)多尺度表示学习：提出了一种显式捕获多尺度关系的图嵌入算法。

2)评价：我们在几个社交网络(如BlogCatalog、DBLP、Flickr、YouTube和Arxiv)上对多标签分类任务的表示进行了广泛的评估。WALKLETS优于Se 像DeepWalk[1]这样的极具挑战性的基线，以5分之多的Micro-F1。

3)可视化与分析：WALKLETS保留了多尺度的潜在表示，用于分析大图中的多尺度效应。

论文的其余部分安排如下。在第二-A节中，我们简要介绍了社交网络的表示学习，并阐述了它们在图形分类问题中的应用。W E.通过分析得出第III节中的多尺度社会表现学习方法，以分析为基础的Walklet。我们在第四节中概述了我们的实验，并给出了它们的结果 在第五节中，我们结束了对第七节中相关工作的讨论，以及我们的结论。

## 2.准备工作

在本节中，我们简要讨论了神经网络表示学习的必要性，因为它涉及我们的工作。

## 3.多尺度神经矩阵分解

在这一部分中，我们将介绍我们的创建多尺度网络表示的算法。我们首先描述我们的模型，以获取不同的表示尺度。接下来，我们将讨论一些问题，比如搜索策略和优化。最后，我们在一个小型的真实世界引文网络上进行了一个案例研究，它说明了通过我们的方法捕获的网络表示。

### A.模型描述

在这里，我们基于II-D1节中建立的直觉基础上，正式扩展了之前的社会表征学习方法，以显式地建模现实世界网络中显示的多尺度效应。

1)DeepWalk的多尺度性质：如方程(5)所示，DeepWalk隐式分解了包含$A, A^{2} \ldots, A^{k}$项的矩阵，其中$k$是随机游动的窗口大小。$A^{k}$的每一个序列代表着不同规模的网络结构。(回想起来，$A_{i j}^{k}$的记录是长度为$k$的节点$i$和$j$之间的路径数)。

因此，很有趣的是，DeepWalk已经在隐式地建模多尺度的依赖关系。这表明，学习到的表示能够同时捕获社交网络中节点之间的短距离和长距离依赖关系。尽管DeepWalk的表现力足以捕捉到这些表示，但它的多尺度属性有其局限性：

**多尺度无保证:**深度行走不一定能捕捉到多尺度表示，因为它们没有被目标函数显式保留。事实上，由于DeepWalk中来自$A$的条目总是比$A^K$的条目多($k>1$)，所以它偏向于保留A的最低幂的表示。要看到这一点，请注意，给定任意长度$L$的随机游动，来自$A$的条目数最多为$L-1$。一般来说，在随机游动中，$A^K$的条目数最多为$\frac{L-1}{k}$。

当高阶幂是网络上机器学习任务的适当表示时，这种倾向于邻接矩阵的低幂是一个根本的弱点。例如, 当对与大比例尺图形结构相关的特征进行分类时，例如社交网络上的语言检测，粗粒度表示可能比保留单个边缘的更精细的表示提供性能上的好处。

**只有全局代表性：**DeepWalk学习一种将所有可能的网络关系规模混为一谈的全局表示。因此，不同的代表比例是无法独立获得的。这是不可取的，因为每个单独的学习任务都需要从全局表示中解码相关的相似信息。在现实中，社会关系的一个理想表现形式是跨越多个尺度，每一个尺度都包含着更广泛层次的潜在社区成员。因此，每个学习任务都能够利用社会关系的最佳水平来完成它的任务。我们将在第五节中说明，每个学习任务的性能可以通过不同的 社会代表。

### B.WALKLETS：多尺度的随机游走

基于迄今讨论的观察结果，我们建议将[1]引入的模型扩展为多尺度依赖关系的显式建模。该方法利用最近提出的学习表示算法，对邻接矩阵$A$的幂进行分解。

类似于DeepWalk，我们通过从每个节点开始的一系列截断随机游动对网络进行建模。正如在[1]中讨论的，在这些截断的随机游动中两个顶点的同时出现可以模拟网络中的扩散速度。然而，我们对采样过程做了一个关键的更改。具体来说，我们选择跳过随机游走中的一些节点。我们表示WALKLETS$\left(A^{1}, \ldots, A^{k}\right)​$分别表示由邻接矩阵的$A^{1}, \ldots, A^{k}​$次幂派生的WALKLETS。

每个不同的力量在一系列语料库中形成一个语料库，该语料库对网络中特定的距离依赖关系进行建模。这个抽样过程如图2所示。

划分按比例抽样的关系之后，在方程3中，我们用顶点$v_{j}$建立了观测样本顶点$v_{i}$的概率模型。

为了学习每个节点$v_{i} \in \mathcal{V}$的表示，这意味着以下目标函数：

$J=-\sum_{v_{i}, v_{j} \in C_{k}} \log \operatorname{Pr}\left(v_{i} | v_{j}\right)$

其中$C_{k}$是为表示标度$k$生成的随机游动对的语料库。$J$试图最大化vi与上下文节点vj共存的日志可能性。这一目标通常称为Skip-gram，最初是为[4]中的语言建模提出的，并首次扩展到[1]中的网络表示学习。

1)损失函数优化：我们用标准反向传播法和随机梯度下降法对方程6中的损失函数进行了优化。我们使用默认的学习速率为0.025，并将嵌入d的大小设置为128个，除非另有说明。这可以很容易地扩展到加权图(通过调整与权重成比例的梯度)。像边缘采样[2]这样的技术也可以适应我们的方法。

2)隐式矩阵分解视图：通过这样的抽样，我们可以显示我们学习不同尺度的表示。在跳过的随机游动上使用DeepWalk，其中跳过因子设置为$k$(我们采样彼此距离为k的节点)。 )隐式地因子从$A^k$导出的矩阵。

观察到，在跳过的具有k跳因子的随机游动中，每个连续的节点对vi和vi 1都可以通过长度正好为k的路径到达，因此表示从$A^k$采样的边缘。当我们为DeepWalk提供与$v_j$共同发生的游动时，只有当它可以通过长度为k的路径到达时，在方程5中，只有对应于$A^k$的项是存在的。因此我们隐式地考虑 由$A^k$导出的矩阵。

3)搜索策略：相关工作[1]、[2]、[9]分别主张从图的边缘生成社会关系的不同策略。广度优先策略从一个感兴趣的节点开始扩展，并检查它的所有邻居。这对本地邻居很有效，但随着扩展程度的提高(即邻居的邻居等)，会面临一种状态空间爆炸。深度优先策略使用随机游走，它编码更长的距离信息，并可能更好地学习高阶网络表示。

我们提出了通过随机游走抽样来观察多尺度关系的方法，我们认为这种方法具有更好的可扩展性。值得一提的是，由于node2vec[9]引入了一种有偏的随机漫步方案，可以看作是DeepWalk的扩展，因此我们的跳过算法也可以应用于它生成的随机漫步。另一种搜索策略(可能用于较小的图)是直接计算$A^{k}​$(即具有长度为k到另一条路径的所有节点)，并使用它对顶点对进行采样。

### C.个案研究：Cora

为了说明网络表示在多尺度上的效果，我们可视化了一个小的引文图Cora，它有2，708个节点和5，429个边。

图3显示了从特定节点(V35)到每个其他节点的社会表示之间的距离的直方图。当我们依次考察更深层次的社会表征时，我们看到一组p 极近节发育。这些节点是更大的论文社区的一部分，$v_{35}​$是遗传算法领域的成员之一。我们应该在Cora进行分类吗？ 网络结构的李尔分离使泛化变得更加容易。

图4也说明了这一现象，图4显示了覆盖在原始网络结构上的节点$v_{35}$的距离热图。请注意不同规模的网络表示的距离。 命名编码的成员资格，在依次较大的社区。

## 4.实验设计

在这一部分中，我们通过将我们的方法应用于几个在线社交网络，对我们的方法进行了实验分析。特别是，我们的实验有两个主要目标：首先，我们试图描述在不同的现实社会网络中表现出的各种多尺度效应。其次，我们评估了我们的方法在捕获其底层网络方面的有效性结构.

我们简要地概述了我们在下面的实验中使用的各种图表：

- BlogCatalog是一个由博客作者之间的关系组成的网络。标签指示与作者关联的主题类别。它包含10，312个节点，333，983个边和39个标签。
- DBLP是计算机科学研究者之间的合著图.标签上标明了研究人员发表的研究领域。它有29，199个节点，133，664个边，和4个标签。
- Flickr是一个由照片分享网站Flickr上的用户组成的网络。网络中的边缘表示用户对之间的接触关系。标签表示兴趣小组。 s的使用者(例如黑色摄影)。它有80，513个节点，5，899，882个边缘和195个标签。
- YouTube是视频爱好者之间的社交图。标签显示用户共享的组成员身份(例如，动画视频)。它有1，138，499个节点，2，990，443个边和47个标签 .

由于我们的方法是以无监督的方式学习社交网络中节点的潜在表示，这些表示通常应该成为各种学习任务的有用特征。 因因此，我们在这样一个重要的任务-社交网络中的多标签分类-上对我们的方法进行了评估。此任务的动机是观察网络中的节点显示成员身份i。 许多团体和他们的朋友是一样的。例如，社交网络中的人是几个圈子的成员(家庭、母校、雇主、共同的爱好等等)。建模和预测这些不同的群体成员不仅仅是Essentia。 l了解真实世界的网络，但也有几个重要的商业应用(例如，更有效的广告目标)。

### A.基线方法

为了与我们的方法进行比较，我们考虑了最近提出的三种社会表征学习模型，它们代表了最先进的社会表征学习模式。

**DeepWalk[1]：**该方法使用截断随机游动序列学习节点的表示。学习的表示在多个尺度上捕获了社区成员的线性组合。

**LINE [2]:**与DeepWalk类似，该方法利用跳格目标函数学习节点表示.对于这个基线，我们使用第1行方法，它只考虑直接连接($A^{1}$中的连接)。

**GraRep[3]**：这种多尺度方法通过显式计算随机游动转移矩阵的逐次幂来生成顶点表示，并利用SVD来降低它们的维数。GraRep是一个非常强大的基线。它在精神上与我们的方法类似，但是GraRep不是一个在线算法，也不会扩展到大图。

### B.多标签分类

我们用[1]中概述的相同的实验方法来评价我们的方法。我们随机抽取标记节点的$T_{f}$部分，并将其用作训练数据，其余部分用作测试数据集。准备好了。这个过程被重复了10次，然后我们报告平均 MICRO-F1分数。我们不包括其他评估指标的结果，如准确性和MACRO-F1，因为它们都遵循相同的趋势。 他也有同样的趋势。这使我们能够轻松地将我们的方法与其他相关基线进行比较。

在所有情况下，我们学习一个Logistic回归模型(基于One和REST策略)分类。我们使用了C=1的缺省L2正则化惩罚，并使用了优化算法实现。 引用文献[10]。

对于WALKLETS，我们只使用从π∈{1，2，3}中的游程生成的表示。在所有情况下，来自每个节点的步行数N被设置为1000，而每个这样的行走L的长度被设置为1。 1。在所有情况下，嵌入d的维度为128(对于所有基线，这些设置也是相同的)。在使用来自π的多个表示的情况下，我们将所有这些特性连接在一起。 并使用PCA将其投影到128个维度。

使用这种方法，我们控制训练数据大小的差异，以及决定表示能力的超参数。这允许进行可解释的比较。 其他方法和基线。

## 5.实验结果

在本节中，我们将介绍我们在第四节中描述的数据集上的多标签分类任务的结果。

> ![1555384912252](F:\Machine-learning-and-data-science-notebook\images\walklet\1555384912252.png)表一：BlogCatalog和DBLP的多标签分类结果。微F1评分报告。通常，特定的高阶表示可以提高任务性能。在DBLP上，(a，好b) )，由GraRep执行的精确多尺度计算优于WALKLETS的抽样方法。大于“深度行走”的数字被粗体显示。(*，*)表示统计性能优越 

A.多标签分类

表一和表二显示了我们的算法的性能和它的增益在两种最先进的网络嵌入方法，即 DeepWalk和LINE。由于它不是一个在线算法，也不会扩展到大的图形(比如Flickr和YouTube)，所以它没有比GraRep更好的表现。

BlogCatalog：表1a显示了BlogCatalog的多标签分类结果.我们观察到，使用A2特性的WALKLETS在Micro-F1方面优于所有基线。当标记数据稀疏时(仅占标记节点的10%)，微F1在0.001水平上的差异有统计学意义(8.9%比DeepWalk提高8.9%，58.4%在线上)。用配对t检验建立了10种不同运行方式的统计显着性.

DBLP：DBLP实验结果见表Ib。我们注意到，A3的表示法提供了一个统计上的显著改善，在微型F1的深度行走和线。带着 1%标记节点，WALKLETS(A3)在深度行走和直线上的增益分别为10.1%和34.3%。这些较粗的表示为作者发布的主题区域提供了更好的编码。

但是，我们注意到，在这个任务上，WALKLETS未能超过GraRep学习的多尺度表示。我们将此归因于DBLP行为良好的事实。首先，它表现出高度的同质性行为，因为共同作者保证了类似的属性(两个a之间的共享发布)。 必须在同一个研究领域)。第二，图中的合著者边表示高度的相似性(很难创建虚假的边)。在此条件下，GraRep直接计算随机游动转移矩阵可以获得较高的性能增益。然而，我们注意到GraRep的技术需要实现稠密的m Atrix，它本质上是不可扩展的-如我们剩余的数据集所示。

Flickr：表IIa显示了对Flickr数据集的评估。在这个数据集上，我们看到从A2派生的特性在micro-f1任务上提供了最好的性能，明显优于所有的性能。 基线。具体来说，我们观察到，当只有1%的数据被标记为训练时，WALKLETS的成绩比DeepWalk高4.1%，在MicroF1评分上则比线高29.6%。

> ![1555392046592](F:\Machine-learning-and-data-science-notebook\images\walklet\1555392046592.png)表二：Flickr和YouTube的多标签分类结果。微F1评分报告。在这些图上，高阶WALKLETS表示优于所有可伸缩的竞争对手。最 竞争基线(GraRep)无法在具有数百万个顶点的图上运行。大于“深度行走”的数字被粗体显示。(*，*)表示在统计上优于o级深度行走的性能 F(0.05，0.001)采用标准配对t检验.

我们注意到，最具竞争力的基线GraRep无法在这个数据集上运行(该数据集只有80，513个顶点)，因为它耗尽了内存。 在产生竞争结果的同时。我们将在第六节中进一步讨论这一问题。

YouTube：我们对YouTube的结果见表IIb。再次，我们的方法优于所有的基线方法。有趣的是，联合表示WALKLETS(A2，A3)提供了BES T表现，在p=0.05水平上显着优于深行和直线。YouTube包含的顶点比我们考虑过的任何其他数据集都多，而且G也就不足为奇了。 raRep再次耗尽内存。我们注意到，WALKLETS的在线设置允许学习具有数百万个顶点的图的表示。