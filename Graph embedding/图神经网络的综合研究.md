# 图神经网络的综合研究

**摘要：**近年来，深度学习彻底改变了许多机器学习任务，从图像分类和视频处理到语音识别和自然语言理解。这些任务中的数据通常表示在欧几里德空间中。然而，越来越多的应用程序从非欧几里德域生成数据，并表示为具有复杂关系和对象之间相互依赖性的图。图数据的复杂性给现有的机器学习算法带来了重大挑战。最近，出现了许多关于扩展图形数据的深度学习方法的研究。在本次调查中，我们提供了数据挖掘和机器学习领域中图形神经网络（GNN）的全面概述。我们提出了一种新的分类法，将最先进的图形神经网络划分为不同的类别。着眼于图卷积网络，我们回顾了最近开发的替代架构;这些学习范例包括图形注意网络，图形自动编码器，图形生成网络和图形时空网络。我们进一步讨论了图神经网络在各个领域的应用，并总结了现有算法在不同学习任务中的开源代码和基准。最后，我们在这个快速发展的领域提出了潜在的研究方向。

关键词：深度学习，图形神经网络，图形卷积网络，图形表示学习，图形自动编码器，网络嵌入

## 1 简介

最近神经网络的成功推动了模式识别和数据挖掘的研究。许多机器学习任务，如对象检测[1]，[2]，机器翻译[3]，[4]和语音识别[5]，曾经严重依赖手工特征工程来提取信息功能集，最近已被由各种端到端深度学习范式，即卷积神经网络（CNN）[6]，长短期记忆（LSTM）[7]和自动编码器彻底改变。在许多领域中深度学习的成功部分归因于快速发展的计算资源（例如，GPU）和大型训练数据的可用性，并且部分归因于深度学习从欧几里德数据中提取潜在表示的有效性（例如，图像，文字和视频）。以图像分析为例，图像可以表示为欧几里德空间中的规则网格。卷积神经网络（CNN）能够利用图像数据的移位不变性，局部连通性和组合性[8]，因此，CNN可以提取与整个数据集共享的局部有意义的特征，用于各种图像分析任务。

虽然深度学习在欧几里得数据上取得了巨大成功，但是有越来越多的应用程序从非欧几里德域生成数据并需要进行有效的分析。例如，在电子商务中，基于图形的学习系统能够利用用户和产品之间的交互[9]，[10]，[11]来提出高度准确的建议。在化学中，分子被建模为图形，并且需要确定它们的生物活性以用于药物发现[12]，[13]。在引文网络中，论文通过引用相互关联，需要将它们分为不同的组[14]，[15]。图数据的复杂性给现有的机器学习算法带来了重大挑战。这是因为图表数据不规则。每个图具有可变大小的无序节点，并且图中的每个节点具有不同数量的邻居，从而导致一些重要的操作（例如，卷积），其在图像域中易于计算，但不直接适用于图域名了。此外，现有机器学习算法的核心假设是实例彼此独立。然而，对于图形数据不是这种情况，其中每个实例（节点）通过一些复杂的链接信息与其他（邻居）相关，这些链接信息用于捕获数据之间的相互依赖性，包括引用，友谊和交互。

最近，人们越来越关注扩展图形数据的深度学习方法。在深度学习成功的推动下，研究人员借用了卷积网络，循环网络和深度自动编码器的思想来设计图神经网络的架构？作品。为了处理图形数据的复杂性，过去几年中，重要操作的新一代化和定义得到了迅速发展。例如，图1说明了一种图形卷积是如何受到标准2D卷积的启发。本调查旨在为想要进入这一快速发展领域的感兴趣的研究人员和想要比较图神经网络算法的专家提供这些方法的全面概述。

图神经网络简史图神经网络的概述首先在Gori等人的文章中概述。 （2005）[16]，并在Scarselli等人进一步阐述。 （2009）[17]。这些早期研究通过迭代方式通过递归神经架构传播邻居信息来学习目标节点的表示，直到达到稳定的固定点。这个过程计算成本很高，最近越来越多的努力克服这些挑战[18]，[19]。在我们的调查中，我们概括了术语图神经网络来表示图数据的所有深度学习方法。

受计算机视觉领域卷积网络巨大成功的启发，最近出现了大量重新定义图形数据卷积符号的方法。这些方法属于图卷积网络（GCN）的保护范围。关于GCN的第一个重要研究在Bruna等人的研究中提出。 （2013），它开发了基于谱图理论的图卷积变体[20]。从那时起，基于频谱的图卷积网络的改进，扩展和近似已经不断增加[12]，[14]，[21]，[22]，[23]。由于光谱方法通常同时处理整个图形并且难以与大图并行或缩放，因此基于空间的图卷积网络最近迅速发展[24]，[25]，[26]，[27]。这些方法通过聚合邻居节点的信息直接在图域中执行卷积。与采样策略一起，计算可以在一批节点中执行，而不是整个图形[24]，[27]，这有可能提高效率。

除了图卷积网络之外，在过去几年中已经开发了许多改变的原生图神经网络。这些方法包括图注意网络，图自动编码器，图生成网络和图时空网络。有关这些方法的类别化的详细信息，请参见第3节。

关于图神经网络的相关调查。关于图神经网络主题的现有评论数量有限。使用符号几何深度学习，Bronstein等。 [8]概述了非欧几里德领域的深度学习方法，包括图形和流形。虽然这是对图形控制网络的第一次审查，但该调查错过了几种重要的基于空间的方法，包括[15]，[19]，[24]，[26]，[27]，[28]，它们更新了状态最先进的基准。此外，这项调查还没有涵盖许多新开发的架构，这些架构对于图形卷积网络同样重要。本文全面回顾了这些学习范式，包括图形注意网络，图形自动编码器，图形生成网络和图形时空网络。 Battaglia等。 [29]位置图网络作为学习关系数据的基石，在统一框架下审查部分图神经网络。然而，他们的通用框架是高度抽象的，从原始论文中失去了对每种方法的见解。李等人。 [30]对图注意模型进行了部分调查，这是一种图神经网络。最近，张等人。 [31]提供了关于图的深度学习的最新调查，遗漏了关于图生成和时空网络的研究。总之，现有的调查都没有提供图神经网络的全面概述，仅覆盖一些图卷积神经网络并检查有限数量的工作，从而忽略了替代图神经网络的最新发展，例如图生成网络和图形时空网络。

关于图神经网络的相关调查。关于图神经网络主题的现有评论数量有限。使用符号几何深度学习，Bronstein等。 [8]概述了非欧几里德领域的深度学习方法，包括图形和流形。虽然这是对图形控制网络的第一次审查，但该调查错过了几种重要的基于空间的方法，包括[15]，[19]，[24]，[26]，[27]，[28]，它们更新了状态最先进的基准。此外，这项调查还没有涵盖许多新开发的架构，这些架构对于图形卷积网络同样重要。本文全面回顾了这些学习范式，包括图形注意网络，图形自动编码器，图形生成网络和图形时空网络。 Battaglia等。 [29]位置图网络作为学习关系数据的基石，在统一框架下审查部分图神经网络。然而，他们的通用框架是高度抽象的，从原始论文中失去了对每种方法的见解。李等人。 [30]对图注意模型进行了部分调查，这是一种图神经网络。最近，张等人。 [31]提供了关于图的深度学习的最新调查，遗漏了关于图生成和时空网络的研究。总之，现有的调查都没有提供图神经网络的全面概述，仅覆盖一些图卷积神经网络并检查有限数量的工作，从而忽略了替代图神经网络的最新发展，例如图生成网络和图形时空网络。图形神经网络与网络嵌入图形神经网络的研究与图形嵌入或网络嵌入密切相关，另一个主题吸引了数据最小化和机器学习社区的关注[32][33] [34][ 35]，[36]，[37]。网络嵌入旨在通过保留网络拓扑结构和节点内容信息来将网络顶点表示为低维向量空间，从而可以通过使用简单的方式轻松执行任何后续图形分析任务，如分类，聚类和推荐现成的学习机算法（例如，用于分类的支持向量机）。
​	许多网络嵌入算法通常是不受限制的算法，它们可以大致分为三组[32]，即矩阵分解[38]，[39]，random walking [40]和深度学习方法。同时用于网络嵌入的深度学习方法属于图形神经网络，其包括基于图形自动编码器的算法（例如，DNGR [41]和SDNE [42]）和具有无需训练的图形卷积神经网络（例如， GraphSage [24]）。图2描述了本文中网络嵌入和图神经网络之间的差异。

我们的贡献：我们的论文作出了显着贡献，总结如下：

- **新的分类：**鉴于越来越多的图形数据深度学习研究，我们提出了一种新的图神经网络分类法（GCNs）。在该分类中，GCN分为五组：图卷积网络，图形关注网络，图形自动编码器，图形生成网络和图形时空网络。我们精确定位了图神经网络和网络嵌入之间的差异，并绘制了不同图神经网络架构之间的联系。

- **全面审查：**本调查提供了有关图形数据的现代深度学习技术的最全面概述。对于每种类型的图神经网络，我们提供有关代表性算法的详细描述，并进行必要的比较和总结相应的算法。

- **丰富的资源：**本调查提供了丰富的图神经网络资源，包括最先进的算法，基准数据集，开源代码和实际应用。该调查可用作实践指南，用于为各种实际应用提供不同的深度学习方法。

- **未来方向：**本调查还强调了现有算法的现有局限性，并指出了这一快速发展领域的可能方向。



  **综述的结构：**本调查的其余部分安排如下。第2节定义了图形相关概念的列表。第3节阐明了图神经网络的分类。第4节和第5节概述了图神经网络模型。第6节介绍了各个领域的应用程序库。
  第7节讨论了当前的挑战并提出了未来方向。第8节总结了论文。

## 2 定义

在本节中，我们提供了基本图形概念的定义。为便于检索，我们总结了表1中常用的符号。

定义1（图）。图是G =（V，E，A），其中V是节点集，E是边集，A是邻接矩阵。在图中，令vi∈V表示节点，eij =（vi，vj）∈E表示边。邻接矩阵A是N×N矩阵，如果eij∈E，则Aij = wij> 0，如果eij∈/ E，则Aij = 0。节点的程度是与其连接的边的数量，正式定义为度（vi） ）= PAi，：

图可以与节点属性X 1相关联，其中X∈RN×D是特征矩阵，其中Xi∈RD表示节点vi的特征向量。在D = 1的情况下，我们用X代替x∈RN来表示图的特征向量。

定义2（有向图）。有向图是所有边指向一个节点到另一个节点的图。对于有向图，Aij 6 = Aji。无向图是所有边都是不定向的图。对于无向图，Aij = Aji。

定义3（空间 - 时间图）。时空图是特征矩阵X随时间演变的归因图。它被定义为G =（V，E，A，X），其中X∈RT×N×D其中T是时间步长。

## 3 分类和框架

在本节中，我们将介绍图神经网络的分类。我们考虑任何将神经结构作为图神经网络的可微图模型。我们将图形神经网络分为图形卷积网络，图形注意网络，图形自动编码器，图形生成网络和图形空间 - 时间网络。其中，图卷积网络在捕获结构依赖性方面发挥着核心作用。如图3所示，其他类别下的方法部分地利用图卷积网络作为构建块。我们总结了表2中每个类别的代表性方法，并在下面简要介绍了每个类别。

### 3.1 GNNs的分类

图形卷积网络（GCN）概括了从传统数据（图像或网格）到图形数据的卷积操作。关键是通过聚合其自身的特征Xi和邻居的特征Xj来学习函数f以生成节点vi的表示，其中j∈N（vi）。图4显示了节点表示学习的GCN过程。图形卷积网络在构建许多其他复杂图形神经网络模型中发挥着核心作用，包括基于自动编码器的模型，生成模型和时空网络等。图5图示了几个基于GCN的图形神经网络模型。

图注意网络类似于GCN，并寻求聚合函数来融合图中的相邻节点，随机游走和候选模型以学习新的表示。关键的区别在于图注意网络采用注意机制，为更重要的节点，步行或模型分配更大的权重。注意力与神经网络一起学习端到端框架内的参数。图6示出了在聚合邻居节点信息时图形卷积网络和图形注意网络之间的差异。

图自动编码器是无监督学习框架，旨在通过编码器学习低维节点向量，然后通过解码器重建图形数据。图自动编码器是学习图嵌入的一种流行方法，对于具有？out属性信息的普通图[41]，[42]以及属性图[61]，[62]。对于普通图，许多算法直接预先设置邻接矩阵，通过构造具有丰富信息的新矩阵（即，逐点互信息矩阵）[41]，或者将邻接矩阵馈送到自动编码器模型并捕获一阶和二阶。信息[42]。对于归因图，图自动编码器模型倾向于使用GCN [14]作为编码器的构建块，并通过链路预测解码器重构结构信息[59]，[61]。

图形生成网络旨在从数据生成合理的结构。给定图形经验分布生成图形具有根本性的挑战性，主要是因为图形是复杂的数据结构。为了解决这个问题，研究人员已经探索过将生成过程视为形成节点和边缘[64]，[65]，以采用生成性对抗训练[66]，[67]。图生成网络的一个有希望的应用领域是化学化合物合成。在化学图中，原子被视为节点，化学键被视为边缘。任务是发现具有某些化学和物理特性的新的可合成分子。

图形时空网络旨在从空间 - 时间图中学习看不见的图像，这在许多应用中越来越重要，例如交通预测和人类活动预测。例如，基础道路交通网络是一个自然图形，其中每个关键位置是连续监测交通数据的节点。
通过开发有效的图形空间时间网络模型，我们可以准确地预测整个交通系统的交通状况[70]，[71]。图时空网络的关键思想是同时考虑空间依赖和时间依赖。许多当前的方法应用GCN来捕获依赖性以及一些RNN [70]或CNN [71]来模拟时间依赖性。

### 3.2 框架

