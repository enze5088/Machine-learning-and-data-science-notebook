# 用于嵌入图的逆正则化图自动编码器

摘要：图嵌入是图形分析中在低维空间中表示图形数据的一种有效方法。现有的嵌入算法大多集中在拓扑结构的保留上。 对图形数据的重构误差进行了重新或最小化，但它们大多忽略了图形中潜在代码的数据分布，这往往导致在现实世界中嵌入较差。 图形数据本文提出了一种新的图数据对抗性图嵌入框架。该框架将图中的拓扑结构和节点内容编码为紧致表示。 在此基础上，对解码器进行训练，以重建图形结构。此外，通过对抗性训练方案执行潜在表示以匹配先验分布。学习 在鲁棒嵌入的基础上，提出了两种对抗性方法，即逆正则图自动编码器(ARGA)和逆正则变分图自动编码器(ARVGA)。经验 对现实世界图形的研究验证了我们的设计，并证明我们的算法在链接预测、图形聚类和图形可视化任务方面远远优于基线。

## 1.介绍

图是捕获和建模数据之间复杂关系的重要工具。在各种图形应用中，包括蛋白质 - 蛋白质相互作用网络，社交媒体和引文网络，分析图形数据在各种数据挖掘任务中起着重要作用，包括节点或图形分类[Kipf和Welling，2016a;Pan et al。，2016a]，链接预测[Wang et al。，2017c]和节点聚类[Wang et al。，2017a]。然而，高计算复杂性，低可并行性以及机器学习方法对图数据的不适用性使得这些图形成为一个具有深刻挑战性的解决方案[Cui et al。，2017]。显然，嵌入图形已成为解决这些问题的一般方法。

图嵌入将图形数据转换成一个低维、紧凑和连续的特征空间。关键是要保留拓扑结构、顶点内容和其他方面的信息[Z]。 Hand等人，2007年a]。这种新的学习模式将寻找复杂的分类、聚类和链接预测模型的任务转移到学习图dat的健壮表示上。 这样，任何图分析任务都可以通过简单的传统模型(例如，用于分类任务的线性支持向量机)轻松地执行。这一优点激发了许多关于这方面的研究。 Area[CAI等人，2017年；戈亚尔和费拉拉，2017年]。

图嵌入算法可分为三大类：概率模型、基于矩阵分解的算法和基于深度学习的算法.像DeepWalk这样的概率模型 [Perozzi等人，2014年]，node2vec[Grover和Leskovec，2016]和line[Tang等人，2015]试图通过从图表中提取不同的模式来学习图形嵌入。捕获的模式或游程包括全局结构等价性、局部邻域连通性和其他各种阶近邻。与经典方法(如谱聚类)的比较 Ng[Tang和Liu，2011]，这些图嵌入算法表现得更有效，并且可扩展到大图。

基于矩阵分解的算法，例如GraRep [Cao et al。，2015]，HOPE [Ou et al。，2016]，M-NMF [Wang et al。，2017b]将图形结构预处理成相邻的算法矩阵并通过分解广告矩阵来获得嵌入。最近已经表明，许多概率算法等价于矩阵分解方法[Qiu et al。，2017]。深度学习方法，特别是基于自动编码器的方法，也被广泛研究用于图形嵌入。SDNE [Wang et al。，2016]和DNGR [Cao et al。，2016]采用深度自动编码器来保持图形邻近度并模拟正向点相互信息（PPMI）。MGAE算法利用边缘化单层自动编码器来学习聚类的表示[Wang et al。，2017a]。

上述方法通常是非正规化的方法，主要侧重于保持结构关系（概率方法），或最小化重构误差（矩阵分解或深度学习方法）。他们大多忽略了这些代码的数据分布。在实践中，非正规嵌入方法通常学习简并身份映射，其中潜在代码空间没有任何结构[Makhzani等，2015]，并且很容易导致在处理现实世界稀疏和噪声图形数据时表现不佳。处理这个问题的一种常见方法是对潜在代码引入一些正则化，并强制它们遵循一些先前的数据分布[Makhzani et al。，2015]。最近生成的基于对抗的框架[Donahue et al。，2016;Radford等人，2015]也被开发用于学习强大的潜在表示。然而，这些框架中没有一个是专门用于图形数据的，其中拓扑结构和内容信息都需要嵌入到潜在空间中。

在本文中，我们提出了一种新的对抗框架，它有两种变体，即对侧正则化图自动编码器（ARGA）和对向正则化变异图自动编码器（ARVGA），用于图嵌入。我们框架的主题不仅是最小化图结构的重构错误，而且还强制执行潜在的代码以匹配先前的分布。通过利用图形概念网络利用图形结构和节点内容，我们的算法对潜在空间中的图形数据进行编码。利用旨在重建拓扑图信息的解码器，我们进一步结合对抗训练方案来规范潜在代码以学习鲁棒图表示。对抗训练模块旨在区分潜在代码是来自真实的先前分布还是来自图形编码器。图形编码器学习和对抗正则化在一个统一的框架中共同优化，这样每个都可以对另一个有益，最终导致更好的图形嵌入。基准数据集的实验结果证明了我们的算法在三个无监督图分析任务中的卓越性能，即链路预测，节点聚类和图形可视化。我们的贡献可以总结如下： 

- 我们提出了一种新的用于图嵌入的异常正则化框架，它表示连续向量空间中的拓扑结构和节点内容。我们的框架学习嵌入以最小化重构错误，同时强制执行潜在代码以匹配先前的分布。
- 我们开发了两种对抗方法，对称正则化图形自动编码器（ARGA）和对侧正则化变分图自动编码器（ARVGA）来学习图形嵌入。
- 基准图数据集上的实验表明，我们的图嵌入方法在三个无监督任务上优于其他方法。

## 2.相关工作

**图嵌入模型**：从形成探索的角度来看，图嵌入算法也可以分为两组：拓扑嵌入方法和内容增强嵌入方法。拓扑嵌入方法假设只有拓扑结构信息可用，学习目标是最大限度地保留拓扑信息。Perozzi等。提出一个DeepWalk模型来学习从一组随机游走中嵌入的节点[Perozzi et al。，2014]。从那时起，开发了许多概率模型，如node2vec [Grover和Leskovec，2016]和LINE [Tang等，2015]。由于图可以在数学上表示为邻接矩阵，因此许多矩阵分解方法如GraRep [Cao等人，2015]，HOPE [Ou等人，2016]，M-NMF [Wang等人，2017b]是建议学习图的潜在表示。最近，深度学习模型被广泛用于学习图形嵌入。这些算法预先设定了第一和第二阶段的邻近性[Wang et al。，2016]，或者通过不同的变换器来重建积极的逐点互信息（PPMI）[Cao et al。，2016]。

内容增强嵌入方法假设节点内容信息可用，并同时利用拓扑结构和内容特征。TADW [Yang et al。，2015]提出了一种基于分析节点特征的矩阵分解方法。TriDNR [Pan et al。，2016b]通过三方神经网络架构捕获结构，节点内容和标签信息。UPP-SNE采用近似的内核映射方案来利用用户配置文件功能来增强社交网络中用户的嵌入式学习[Zhang et al。，2017b]。

不幸的是，上述算法在很大程度上忽略了嵌入的分布，这可能导致在实践中表现不佳。在本文中，我们探讨了逆向训练方法来解决这个问题。

对抗模型。我们的方法是由生成对抗网络（GAN）推动的[Goodfellow et al。，2014]。GAN使用两个链接模型进行对抗游戏：生成器G和鉴别器D.鉴别器可以是多层感知器，可以区分输入样本是来自数据分布还是来自我们构建的生成器。同时，训练发生器以产生样本以说服鉴别器生成的样本来自先前的数据分布。由于其在许多无监督任务中的有效性，最近提出了许多对抗性训练算法[Donahue et al。，2016; Radford等，2015]。

## 3.问题定义和框架

图表示为G={V，E，X}，其中V={vi}i=1，···，n由图中的一组节点组成，EI，j=<vi，vj>∈E表示编码节点之间引用边的链接 s。图G的拓扑结构可以用邻接矩阵A来表示，其中AI，j=1，若EI，j∈E，否则为AI，j=0。XI∈X表示与每个节点vi相关联的内容特征。

给定图G，我们的目的是将节点vi∈V映射到低维向量zi∈Rd，形式如下：f：（A，X）？Z，其中z> i是矩阵Z∈Rn×d的第i行。n是节点数，d是嵌入的维数。我们将Z作为嵌入矩阵，嵌入应该很好地保留拓扑结构A以及内容信息X.

### 3.1 总体框架

我们的目标是学习一个鲁棒嵌入图G={V，E，X}。为此，我们利用带有图形自动编码器的对抗性体系结构直接处理整个图并学习。 一个健壮的嵌入。图1演示了Arga的工作流，它由两个模块组成：图形自动编码器和对抗性网络。

- **图形卷积自动编码器：**自动编码器将图A的结构和节点内容X作为输入来学习潜在表示Z，然后从Z重构图结构A.
- **对抗性正规化：**对抗性网络通过对抗性训练模块强制潜在代码与先验分布相匹配，从而判断当前的潜在代码zi∈Z是否与先验分布相匹配。 来自编码器或先前的分布。

## 4提出的算法

### 4.1图形卷积自动编码器

图形卷积自动编码器旨在在低维空间中嵌入图形G = {V，E，X}。出现了两个关键问题：（1）如何在编码器中集成图形结构A和节点内容X，以及（2）应该通过解码器重建哪种信息？

图形卷积编码器模型G（X，A）。为了在统一框架中代表图形结构A和节点内容X，我们开发了图形卷积网络（GCN）[Kipf和Welling，2016a]的变体作为图形编码器。我们的图卷积网络（GCN）将卷积的运算扩展到谱域中的图数据，并通过谱卷积函数f（Z（l），A | W（l））学习分层变换：

$\mathbf{Z}^{(l+1)}=f\left(\mathbf{Z}^{(l)}, \mathbf{A} | \mathbf{W}^{(l)}\right)$

这里，Zl是卷积的输入，Z(L1)是卷积后的输出。对于我们的问题，我们有Z0=X∈Rn×m(n个节点和m个特征)。W(L)是我们需要的滤波器参数矩阵 在神经网络中学习。如果f(Z(L)，A_x~(W(L)定义良好，则可以有效地建立任意深度卷积神经网络。

我们的图卷积网络的每一层都可以用函数f(Z(L)，A_\W(L)表示如下：$f\left(\mathbf{Z}^{(l)}, \mathbf{A} | \mathbf{W}^{(l)}\right)=\phi\left(\widetilde{\mathbf{D}}^{-\frac{1}{2}} \widetilde{\mathbf{A}} \tilde{\mathbf{D}}^{-\frac{1}{2}} \mathbf{Z}^{(l)} \mathbf{W}^{(l)}\right)$

其中Ae=Ai和de II=Pj Ae ij。I是A的单位矩阵，φ是一个激活函数，如Relu(T)=max(0，t)或Sigmoid(T)=1.1et。总的来说，图编码器G(X，A)是负的。 用两层GCN运输。在本文中，我们开发了两个变体的编码器，即图编码器和变分图编码器。

图形编码器的构造如下：

$\mathbf{Z}^{(1)}=f_{\text { Relu }}\left(\mathbf{X}, \mathbf{A} | \mathbf{W}^{(0)}\right)$ 

$\mathbf{Z}^{(2)}=f_{\text { linear }}\left(\mathbf{Z}^{(1)}, \mathbf{A} | \mathbf{W}^{(1)}\right)$

对于第一层和第二层使用了relu(·)和线性激活函数。我们的图卷积编码器G(Z，A)=q(Z，X，A)将图的结构和节点内容编码成一个表示。 $\mathbf{Z}=q(\mathbf{Z} | \mathbf{X}, \mathbf{A})=\mathbf{Z}^{(2)}$

变分图编码器是由一个推理模型定义的：

$q(\mathbf{Z} | \mathbf{X}, \mathbf{A})=\prod_{i=1}^{n} q\left(\mathbf{z}_{\mathbf{i}} | \mathbf{X}, \mathbf{A}\right)$

 $q\left(\mathbf{z}_{\mathbf{i}} | \mathbf{X}, \mathbf{A}\right)=\mathcal{N}\left(\mathbf{z}_{i} | \boldsymbol{\mu}_{i}, \operatorname{diag}\left(\sigma^{2}\right)\right)$

这里，mr=Z(2)是均值向量Zi的矩阵；同样，logσ=fl线性(Z(1)，A~xW0(1)，它与Eq的第一层中的权重W(0)共享。(3)。

解码器模型。我们的解码器模型用于重建图形数据。我们可以重建图结构A，内容信息X或两者。在我们的论文中，我们提出重建图形结构A，它提供了更大的灵活性，即使没有可用的内容信息X（例如，X = 1），我们的算法仍将正常运行。我们的解码器p（A | Z）预测两个节点之间是否存在链接。更具体地说，我们基于图形嵌入训练链接预测层：

$p(\hat{\mathbf{A}} | \mathbf{Z})=\prod_{i=1}^{n} \prod_{j=1}^{n} p\left(\hat{\mathbf{A}}_{i j} | \mathbf{z}_{i}, \mathbf{z}_{j}\right)$
$p\left(\hat{\mathbf{A}}_{i j}=1 | \mathbf{z}_{i}, \mathbf{z}_{j}\right)=\operatorname{sigmoid}\left(\mathbf{z}_{i}^{\top}, \mathbf{z}_{j}\right)$

图形自动编码器模型嵌入Z和重构图Aˆ可表示如下：

优化。对于图形编码器，我们通过以下方法将图形数据的重构误差降到最小：

$\mathcal{L}_{0}=\mathbb{E}_{q(\mathbf{Z} |(\mathbf{X}, \mathbf{A}))}[\log p(\hat{\mathbf{A}} | \mathbf{Z})]$

对于变分图编码器，我们对变分下界进行了如下优化：

$\mathcal{L}_{1}=\mathbb{E}_{q(\mathbf{Z} |(\mathbf{X}, \mathbf{A}))}[\log p(\hat{\mathbf{A}} | \mathbf{Z})]-\mathbf{K L}[q(\mathbf{Z} | \mathbf{X}, \mathbf{A}) \| p(\mathbf{Z})]$

其中，$\mathbf{K L}[q(\bullet) \| p(\bullet)]$是$q(\bullet)$ and $p(\bullet)$之间的Kullback-Leiber散度。我们也取高斯先验$p(\mathbf{Z})=\prod_{i} p\left(\mathbf{z}_{i}\right)=\prod_{i} \mathcal{N}\left(\mathbf{z}_{i} | 0, \mathbf{I}\right)$

### 4.2 对抗式$\mathcal{D}(\mathbf{Z})$

我们模型的关键思想是强制潜在表示Z匹配先前的分布，这是通过广告训练模型实现的。对抗模型建立在标准的多层感知器（MLP）上，其中输出层仅具有一个具有S形函数的维度。adver？sarial模型充当鉴别器，以区分潜在代码是来自先前的pz（正）还是来自图形编码器$\mathcal{G}(\mathbf{X}, \mathbf{A})$（负）。通过最小化训练二元分类器的交叉熵成本，嵌入最终将在训练过程中被规范化和改进。
费用可按如下方式计算： 

$-\frac{1}{2} \mathbb{E}_{\mathbf{z} \sim p_{z}} \log \mathcal{D}(\mathbf{Z})-\frac{1}{2} \mathbb{E}_{\mathbf{X}} \log (1-\mathcal{D}(\mathcal{G}(\mathbf{X}, \mathbf{A})))$

在本文中，我们使用简单的高斯分布作为PZ分布。对抗性图自动编码模型。用判别器D(Z)训练编码器模型的公式可以写成：$\min _{\mathcal{G}} \max _{\mathcal{D}} \mathbb{E}_{\mathbf{z} \sim p_{\boldsymbol{z}}}[\log \mathcal{D}(\mathbf{Z})]+\mathbb{E}_{\mathbf{x} \sim p(\mathbf{x})}[\log (1-\mathcal{D}(\mathcal{G}(\mathbf{X}, \mathbf{A})))]$

其中G(X，A)和D(Z)表示上述的发生器和判别器.

4.3 算法解释

算法1是我们提出的框架。给定图G，步骤2从图卷积编码器中得到潜在变量矩阵Z。然后，我们从生成的 Z和实际数据分布pz分别在步骤4和步骤5中，用步骤6中计算的交叉熵代价更新鉴别器。经过K次训练鉴别器后，图继续运行。 der将试图混淆经过训练的鉴别器，并在步骤7中用生成的梯度更新自己。我们可以更新Eq。(10)训练逆正则图自动编码器(ARGA)。(1) 1)分别训练逆正则变分图自动编码器(ARVGA)。最后，我们将在步骤8中返回嵌入Z∈Rn×d的图。

## 5 实验

我们报告了三种无监督图分析任务的结果：链接预测、节点聚类和图形可视化。表1总结了本文使用的基准图数据集。 每个数据集由作为节点的科学出版物和作为边的引用关系组成。每个文档中的特征都是独特的。

### 5.1 链接预测基线。

我们将我们的算法与最先进的链接预测任务算法进行了比较：

> ![1556281465600](F:\Machine-learning-and-data-science-notebook\images\用于嵌入图的逆正则化图自动编码器\1556281465600.png)
>
> - DeepWalk [Perozzi et al。，2014]：是一种网络表示方法，它将社会关系编码为连续的向量空间.
> - 谱聚类[Tang and Liu，2011]：是一种有效的学习社交嵌入的方法。
> - GAE [Kipf and Welling，2016b]：是最新的基于自动编码器的图形数据无监督框架，它自然地利用了拓扑和内容信息。
> - VGAE [Kipf and Welling，2016b]：是一种变分图自动编码器方法，用于图形嵌入，包括拓扑和内容信息。
> - ARGA：我们提出的异常正则化自动编码器算法，它使用图形自动编码器来学习嵌入。
> - ARVGA：我们提出的算法，它使用变异图自动编码器来学习嵌入。

指标。我们根据AUC分数（接收器操作特征曲线下的面积）和平均精度（AP）[Kipf和Welling，2016b]得分报告结果。我们进行10次每次实验并报告平均值，标准误差作为最终得分。每个数据集分为训练，测试集和验证集。验证集包含用于超参数优化的5％引用边，测试集保持10％引文边以验证性能，其余用于训练。

参数设置。对于Cora和Citeseer数据集，我们训练所有与自动编码器相关的模型进行200次迭代，并使用Adam算法对其进行优化。学习率和鉴别器学习率均设为0.001。由于PubMed数据集相对较大（约20,000个节点），我们迭代2,000次进行适当的训练，具有0.008的辨别学习率和0.001学习率。我们为所有实验构建具有32-神经元隐藏层和16-神经元em？垫层的编码器，并且所有判别器都构建有两个隐藏层（分别为16-神经元，64-神经元）。对于其余的基线，我们保留相应论文中描述的设置。

实验结果。关于链路预测的实验结果的详细信息如表2所示。结果表明，通过在我们的图卷积自动编码器中加入有效的对抗训练模块，ARGA和ARVGA实现了出色的性能：所有AP和AUC分数均为所有三个数据集均高达92％。与所有基线相比，ARGE将AP得分从2.5％增加到与带有节点功能的VGAE相比，11％与没有节点功能的VGAE相比;与大型PubMed数据集上的DeepWalk和Spec？tral Clustering相比分别为15.5％和10.6％。

参数研究。我们将嵌入的维度从8个神经元改变为1024个，并在图2中报告结果。
		图2（A）和（B）的结果揭示了类似的趋势：当将8个神经元的嵌入维数加到16个神经元时，嵌入链接预测的性能稳步提高; 但是当我们进一步将嵌入层的神经元数量增加到32-神经元时，性能会波动，但AP得分和AUC得分的结果仍然很好。
		值得一提的是，如果我们继续设置更多的神经元，例如64神经元，128神经元和1024神经元，性能会显着提高。

### 5.2 节点聚类

对于节点聚类任务，我们首先学习图嵌入，然后在嵌入的基础上执行K-均值聚类算法。

基线。我们比较了基于嵌入的方法以及直接用于图聚类的方法。除了我们对链接预测进行比较的基线外，我们还包括为聚类设计的基线：

1.K-means是一种经典方法，也是许多聚类算法的基础。
		2.图编码器[Tian et al。，2014]学习用于谱图聚类的图嵌入。

3. DNGR [Cao et al。，2016]训练堆叠去噪自动编码器进行图形嵌入。
4. RTM [Chang and Blei，2009]从文本和引文中学习每个文档的主题分布。
5. RMSC [Xia et al。，2014]采用多视图学习方法进行图聚类。
6. TADW [Yang et al。，2015]将矩阵分解应用于网络表示学习。

在这里，前三种算法只使用图结构，而最后三种算法在图聚类任务中同时使用图结构和节点内容。

指标。在[夏等人，2014]之后，我们使用五个指标来验证聚类结果：准确性(ACC)、归一化互信息(NMI)、精度、F-评分(F1)和平均Rand指数( Aerospace Research Incorporation <美>航空航天研究公司).

实验结果。Cora和Citeseer数据集的聚类结果在表3和表4中给出。结果表明，与所有其他基线相比，ARGA和ARVGA在所有五个指标上都取得了显着的进步。例如，在Citeseer上，与K-means相比，ARGA将准确率从6.1％提高到与GraphEncoder相比的154.7％;与DeepWalk相比，F1比分从TADW的31.9％提高到102.2％;与K-means相比，NMI从14.8％增加到与VGAE相比增加到124.4％。ARGE和GAE（以及其他）之间结果的广泛差距进一步证明了我们的对称正则化图自动编码器的优越性。

### 5.3 图形可视化

我们将Cora数据可视化在一个二维空间中，将t-SNE算法应用于学习到的嵌入上。图3中的结果通过应用 对图数据进行训练，可以得到更有意义的图数据布局。

## 6 结论

在本文中，我们提出了一种新颖的对抗图嵌入图框架数据框架。我们认为大多数现有的图嵌入算法都是非规范化的方法，它们忽略了潜在表示的数据分布，并且在现实世界的图形数据中遭受较差的嵌入。我们提出了一种对抗性培训方案，以规范这些代码并强制执行潜在的代码以匹配先前的分配。利用图形卷积自动编码器联合学习对抗模块以产生稳健的表示。
	实验结果表明，我们的算法ARGA和ARVGA在链路预测，节点聚类和图形可视化任务方面优于基线。该研究由澳大利亚政府通过澳大利亚研究委员会（ARC）资助，资助1）LP160100630与澳大利亚政府卫生部合作，2）LP150100671与澳大利亚儿童和青少年研究联盟（ARACY）和澳大利亚全球商业学院合作（ GBCA）。
我们感谢NVIDIA公司和MakeMagic Australia的支持，并捐赠了用于本研究的GPU。