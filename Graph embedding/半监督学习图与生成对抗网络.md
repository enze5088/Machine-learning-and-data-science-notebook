# 生成对抗网图的半监督学习

摘要：我们研究了生成对抗性网(GANS)如何帮助对图的半监督学习。我们首先提供关于图的对抗性学习的工作原理的见解，然后介绍。 GraphSGAN是一种对图进行半监督学习的新方法.在GraphSGAN中，生成器和分类器网络是一种新的竞争博弈。在平衡时，生成器在子图之间的低密度区域生成假样本。为了区分假样本和实样本，分类器隐式地考虑了子图的密度特性。为了改进传统的归一化图拉普拉斯正则化方法，提出了一种有效的对抗性学习算法。

对几种不同类型的数据集的实验结果表明，所提出的GraphsGan显著优于几种最先进的方法。graphsgan还可以使用mini-batch进行培训，因此具有可扩展性优势。

## 1.简介

图的半监督学习在理论和实践中都引起了广泛的关注。它的基本设置是给我们一个由一小组标记节点和一大组未标记节点组成的图，目的是学习一个可以预测未标记节点标签的模型。

关于图的半监督学习有一长串的工作。研究的一个重要范畴主要是基于图拉普拉斯正则化框架。例如，朱等。[41]提出了一种标签传播方法，用于从图上的有标签和无标签数据中学习数据，后来在bootstrap迭代框架下，由lu和getoor[20]对该方法进行了改进。Blum和Chawla[4]还将图学习问题定义为在图上找到最小割集。朱等。[42]提出了一种基于高斯随机场和形式化图拉普拉斯正则化框架的算法。Belkin等人[2]提出了一种利用边缘分布几何进行半监督学习的正则化方法。第二类研究是将半监督学习与图形嵌入相结合。韦斯顿等人[37]首先将深度神经网络纳入图拉普拉斯正则化框架，用于半监督学习和嵌入。Yang等人[38]提出了联合学习嵌入图和预测节点标签的规划模型。最近，Deffrard等人[9]利用局部谱切比雪夫滤波器对机器学习任务的图形进行卷积。图卷积网络（GCN）[17]及其基于注意技术的扩展[34]在这一问题上显示出巨大的威力并取得了最新的性能。

本文研究了生成对抗网在图形半监督学习中的应用潜力。gans[13]最初是为生成图像而设计的，通过训练两个神经网络来玩最小-最大博弈：鉴别器d尝试区分真实样本和假样本，生成器g尝试生成“真实”样本来欺骗鉴别器。据我们所知，关于使用gan对图进行半监督学习的工作很少。

本文提出了一种新的基于Gans图的半监督学习方法。graphsgan将图形拓扑映射到特征空间，并联合训练生成器网络和分类器网络。以前的工作[8，18]试图解释半监督GANS的工作原理，但只发现在互补区域生成中等程度的假样本有利于分类和在强假设下进行分析。本文从博弈论的角度阐述了该模型的工作原理。我们有一个有趣的观察，在子图之间的低密度区域的假样本可以减少附近样本的影响，从而有助于提高分类精度。在这一观察的指导下，设计了一种新颖的类GAN游戏。精密的损耗保证了发生器在这些低密度区域产生平衡的样品。此外，结合观测结果，图拉普拉斯正则化框架（方程（9））可以利用聚类特性取得稳定进展。从理论上证明了这种对抗性学习技术能够对具有丰富而有限生成样本的图进行完全的半监督学习。

提出的GraphSGAN是在几种不同类型的数据集上进行评估的。实验结果表明，GraphSGAN的性能明显优于几种最先进的方法.GraphSGAN也可以 使用小型批处理进行培训，因此具有可扩展性优势.

我们的贡献如下：

- 我们引入GANS作为解决半监督设置下图的分类任务的工具.GraphSGAN在图中的低密度区域生成假样本，并利用聚类特性 帮助分类
- 我们为GraphSGAN在发生器和鉴别器之间制定了一种新颖的竞争博弈，并在训练过程中对动态，均衡和工作原理进行了深入分析。此外，我们概括了工作原理以改进传统算法。我们的理论证明和实验验证都勾勒出了这种方法的有效性
- 我们以不同的比例对我们的模型进行了评估。GraphSgan显著优于以前的工作，并显示出卓越的可扩展性。

本文的其余部分安排如下。在第2节中，我们介绍了必要的定义和GAN。在第3节中，我们介绍GraphSGAN并讨论模型的详细设计原因和方式。第4节给出了GraphSGAN背后工作原理的理论分析。我们在第5节中概述了我们的实验，并展示了我们模型的优越性。最后，我们将结束第6节中的相关工作和我们的结论。

## 2.准备工作

### 2.1 问题定义

设G =（V，E）表示图，其中V是一组节点，E⊆V×V是一组边。假设每个节点v i与k维实值特征向量wi∈Rk和标签yi∈{0，...，M-1}相关联。如果节点v i的标签y i未知，我们说节点v i是未标记的节点。我们将标记节点集表示为V L，将未标记节点集表示为V U = V \ V L.通常，我们有| V L | «| V U | 。我们还将图G称为部分标记图[31]。鉴于此，我们可以在图上正式定义半监督学习问题。

定义1.图形上的半监督学习。给定部分标记的图G =（VL∪VU，E），这里的目的是使用与每个节点和图形结构相关联的特征w来学习函数f，以便预测图中未标记节点的标签。

请注意，在半监督学习中，培训和预测通常同时进行。在这种情况下，学习考虑标记的节点和未标记的节点，以及整个图的结构。在本文中，我们主要考虑转换学习设置，尽管所提出的模型也可以应用于其他机器学习设置。此外，我们只考虑无向图，但有向图的扩展是直截了当的

> ![1560325398831](F:\Machine-learning-and-data-science-notebook\images\半监督学习图与生成对抗网络\1560325398831.png)

> 图1：GraphSGAN中工作原理的定性说明。两个标记的节点分别为纯蓝色和纯橙色，所有其他节点均为未标记的节点。左图是香草标签传播算法的一个坏例子。在这种情况下，nodev3由于其与节点v +的直接链接而被分配了错误的标签。右图说明了GraphSGAN的工作原理。它在密度间隙中生成假节点（黑色），从而减少节点在密度间隙中的影响。

### 2.2 生成性对抗网（GAN）

GAN [13]是一种通过对抗过程估计生成模型的新框架，其中生成模型G被训练以最佳地拟合原始训练数据，并且训练辨别模型D以区分真实样本和由模型G生成的样本。该过程可以形式化为G和D之间的最小 - 最大游戏，具有以下损失（值）函数：

$\min _{G} \max _{D} V(G, D)=\mathbb{E}_{\mathbf{x} \sim p_{d}(\mathbf{x})} \log D(\mathbf{x})+\mathbb{E}_{\mathbf{z} \sim p_{z}(\mathbf{z})} \log [1-D(G(\mathbf{z}))]$

其中$p_{d}$是来自训练数据的数据分布，$p_{z}(\mathbf{z})$是输入噪声变量的先验

## 3.模型框架

### 3.1动机

我们现在介绍如何利用GAN的功能进行半监督学习而不是图形。直接将GAN应用于图形学习是不可行的，因为它不考虑图形结构。为了说明GAN如何帮助半监督学习图形，我们从一个例子开始。图1中的左图显示了基于图形的半监督学习的典型示例。两个标记的节点分别为蓝色和橙色。诸如Label Propagation [41]之类的传统方法不考虑图形拓扑，因此无法区分从节点v +到节点v1，v2和v3的传播。仔细看看图结构，我们可以看到有两个子图。我们将这两个子图之间的区域称为密度差距。

我们的想法是使用GAN估计密度子图，然后在密度间隙区域生成样本。然后，我们首先请求分类器在将假样本分类到不同的类之前区分它们。以这种方式，将伪样本与实际样本区分开将导致围绕密度间隙的学习分类函数的较高曲率，这削弱了跨密度间隙的传播效果（如图1的右图所示）。同时在每个子图内部，由于监督损失减少和一般平滑技术（例如随机层），对正确标签的置信度将逐渐提高。更详细的分析将在第5.2节中报告。

### 3.2 架构

基于GAN的模型不能直接应用于图形数据。为此，GraphSGAN首先使用网络嵌入方法（例如，DeepWalk [23]，LINE [29]或NetMF [24]）来学习每个节点的潜在分布式表示qi，然后将潜在分布qi与原始特征连接起来 矢量wi，即xi =（wi，qi）。最后，xi被作为我们方法的输入。

> ![1560502568002](F:\Machine-learning-and-data-science-notebook\images\半监督学习图与生成对抗网络\1560502568002.png)图2：我们模型的概述。假生成器生成假输入，并通过连接原始特征wi和学习嵌入qi来获取实际输入。由发生器生成的实际输入和假样本都被馈送到分类器中。

图2显示了GraphSGAN的体系结构。GraphSGAN中的分类器D和生成器G都是多层感知器。更具体地，发生器将高斯噪声z作为输入并输出具有与xi相似形状的伪样本。在生成器中，使用批量标准化[15]。发生器的输出层受到重量归一化技巧[27]的约束，具有可训练的体重秤。GAN中的鉴别器由分类器代替，其中在输入和全连接层之后添加随机层（加性高斯噪声）以用于平滑目的。在预测模式中消除噪声。全连接层中的参数受到用于正则化的权重归一化的约束。分类器h（n）（x）中最后一个隐藏层的输出是通过输入x的非线性变换提取的特征，这对于训练生成器时的特征匹配[26]是必不可少的。分类器以（M + 1） - 单元输出层和softmax激活结束。单元0到单元M M 1的输出可以解释为不同类别的概率，单元M的输出表示假的概率。实际上，我们只考虑前M个单位并假设伪类PM的输出在softmax之前始终为0，因为在softmax之前从所有单位中减去相同的数字不会改变softmax结果。

### 3.3 学习算法

#### 3.3.1 博弈与均衡

GAN尝试生成类似于训练数据的样本，但我们希望在密度差距中生成假样本。因此，优化目标必须与提出的GraphSGAN模型中的原始GAN不同。为了更好地解释，我们从博弈论的更一般的角度重新审视GAN。

在普通的双人游戏中，G和D都有自己的损失功能，并尽量减少它们。他们的损失是相互依存的。我们表示损失函数LG（G，D）和LD（G，D）。效用函数VG（G，D）和VD（G，D）是负损耗函数。

GAN定义了一个零和游戏，其中LG（G，D）= -LD（G，D）。在这种情况下，minimax策略可以达到唯一的纳什均衡[35]。找到均衡相当于解决优化问题： 

$ \ min _ {G} \ max _ {D} V_ {D}（G，D）$

Goodfellow等人。[13]证明ifVD（G，D）定义为方程式1，G将生成受均衡数据分布的样本。生成样本的分布pд（x）是实数据pd（x）的分布的近似值。但我们希望在密度差距中生成样本，而不是仅仅模仿真实数据。因此，原始GAN无法解决此任务。

在提出的GraphSGAN中，我们修改LD（G，D）和LG（G，D）来设计一个新的游戏，其中G将在均衡中产生密度差距的样本。更确切地说，我们期望真实样本和假样本在其最终代表层h（n）（x）中如图3所示映射。因为“有效性差距”的概念在代表层比在图形中更直接，我们定义节点位于密度间隙中，当且仅当它位于h（n）（x）层的密度间隙中时。如何将节点映射到代表层将在3.2节中解释。

设计背后的直觉是基于着名的现象，称为“维度”[10]。在像h（n）（x）这样的高维空间中，中心区域比外部区域窄得多。中心区域的训练数据很容易成为枢纽[25]。集线器经常出现在其他类别样本的最近邻居中，这可能会严重影响半监督学习并成为主要难点。因此，我们希望中心区域成为密度差距而不是集群之一。

我们将LD（G，D）和LG（G，D）定义如下，以保证预期的均衡：

$\begin{aligned} \mathcal{L}_{D} &=\operatorname{loss}_{s u p}+\lambda_{0} \operatorname{loss}_{u n}+\lambda_{1} \operatorname{loss}_{e n t}+\operatorname{loss}_{p t} \\ \mathcal{L}_{G} &=\operatorname{loss}_{f m}+\lambda_{2} \operatorname{loss}_{p t} \end{aligned}$

接下来，我们将解释LD（G，D）和LG（G，D）中的这些损失项以及它们如何在细节中生效。



#### 3.3.2判别性损失。

在均衡状态下，任何球员都无法改变策略以单方面减少损失。假设G在均衡的中心区域生成样本，我们为D提出了四个条件，以保证h（n）（x）中的预期均衡。

（1）来自不同类的节点应映射到不同的集群。
		（2）标记和未标记的节点都不应映射到中心区域，以使其成为密度间隙。
		（3）每个未标记的节点应映射到表示特定标签的一个簇中。
		（4）不同的集群应该足够远。

满足条件（1）的最自然的方式是监督损失失败。losssup被定义为M类预测分布与真实标签的单热表示之间的交叉熵。

$\operatorname{loss}_{s u p}=-\mathbb{E}_{\mathbf{x}_{i} \in X^{L}} \log P\left(y_{i} | \mathbf{x}_{i}, y_{i}<M\right)$

其中X L是标记节点V L的输入集。

条件（2）等同于原始GAN中D的目标，假设G在中心密度间隙中生成假样本。因此，我们仍然使用等式1中的损失并称之为损失。当真实或假的错误分类发生时，分类器D会引起损失。

$\begin{aligned} \operatorname{loss}_{u n}=&-\mathbb{E}_{\mathbf{x}_{i} \in X^{U}} \log \left[1-P\left(M | \mathbf{x}_{i}\right)\right] \\ &-\mathbb{E}_{\mathbf{x}_{i} \sim G(\mathbf{z})} \log P\left(M | \mathbf{x}_{i}\right) \end{aligned}$

其中X U是未标记节点V U的预处理输入的集合;G（z）是生成样本的分布;并且P（M | xi）表示xi的预测假概率。

条件（3）请求D为每个未标记的节点分配明确的标签。我们通过添加熵调节项lossent，M标签上的分布熵来解决该问题。熵是概率分布不确定性的度量。它已成为长期半监督学习中的正则化术语[14]，并且首先与[28]中的GAN相结合。减少熵可以鼓励分类器为每个节点确定明确的标签。

loss$_{e n t}=-\mathbb{E}_{\mathbf{x}_{i} \in X^{U}} \sum_{y=0}^{M-1} P\left(y | \mathbf{x}_{i}, y_{i}<M\right) \log P\left(y | \mathbf{x}_{i}, y_{i}<M\right)$



条件（4）扩大了密度差距以帮助分类。我们利用拉开期限损失[39]来满足它。losspt最初设计用于在普通GAN中生成不同的样本。它是批次中矢量之间的平均余弦距离。它使h（n）（x）层中的表示尽可能远离其他层。
因此，它也鼓励群集远离其他群集。

其中xi，xj在同一批次中，m是批量大小。

#### 3.3.3 生成损失。

同样，假设D满足上述四个条件，我们还有两个条件让G保证h（n）（x）中的预期均衡：

（1）G生成映射到中心区域的样本。
		（2）生成的样本不应该在唯一的中心点过度拟合。

对于条件（1），我们使用特征匹配损失训练G [26]。它最小化了生成的样本与实际样本的中心点之间的距离$\mathbb{E}_{\mathbf{x}_{i} \in X} U_{\cup X^{L}} h^{(n)}\left(\mathbf{x}_{i}\right)$。实际上，在训练过程中，中心点被实际批次Exi鈭圶批次h（n）（xi）中的样本中心取代，这有助于满足条件（2）。距离最初以L2范数测量。（但是，在实践中，我们发现L1规范也运行良好，性能稍好一些。）

$\operatorname{loss}_{f m}=\left\|\mathbb{E}_{\mathbf{x}_{i} \in X_{b a t c h}} h^{(n)}\left(\mathbf{x}_{i}\right)-\mathbb{E}_{\mathbf{x}_{j} \sim G(\mathbf{z})} h^{(n)}\left(\mathbf{x}_{j}\right)\right\|_{2}^{2}$

条件（2）请求生成的样本以覆盖尽可能多的中心区域。我们还使用拉脱损失项（公式6）来保证满足这个条件，因为它鼓励年龄G生成不同的样本。在中心性和多样性之间需要权衡，因此我们使用超参数位2来平衡损失和损失。D中的随机层为假输入添加了噪声，这不仅提高了鲁棒性，还防止了伪样本过度拟合。

#### 3.3.4 训练

GAN通过迭代地最小化D和G的损失来训练D和G.在博弈论中，它被称为近视最佳反应[1]，一种有效的启发式方法来寻找平衡。GraphSGAN也以这种方式进行训练。

训练的第一部分是将图中的节点转换为特征空间中的向量。我们使用LINE [29]进行q的预处理，它在我们的数据集上执行快速和稳定。我们还测试了其他网络嵌入算法，并在分类中找到了类似的性能。为了加速收敛，使用邻域融合技术重新计算节点的特征。设N e（vi）为vi的邻居集合，节点vi  - 权重由以下重新计算：

$\mathbf{w}_{i}^{\prime}=\alpha \mathbf{w}_{i}+\frac{1-\alpha}{\left|N e\left(v_{i}\right)\right|} \sum_{v_{j} \in N e\left(v_{i}\right)} \mathbf{w}_{j}$

邻居融合思想类似于使用注意机制的预处理技巧[34]。

在主训练循环中，我们迭代地训练D和G.为了计算LD，我们分别需要三批标记的，未标记的和生成的样本。losssup需要标记数据。lossun是根据未标记和生成的数据计算的。理论上，lossun还应该考虑标记数据，以确保它们被分类为真实的。但是losssup已经将标记数据正确分类为真实标签，因此没有必要在lossun中考虑标记数据。lossent只考虑未标记的数据和丢失应该“不管”标记和未标记的数据。通常需要三个超参数来平衡四个损失的尺度。我们在GraphSGAN中仅使用两个参数位0和位1，因为由于在半监督设置下很少标记的样本，losssup将很快被优化到接近0。

训练G需要实际和生成的批量数据。lossf m比较h（n）（x）中实数和生成数据的批处理中心，losspt测量生成数据的多样性。我们总是希望G在中心区域生成样本，这是在3.3.2节讨论LD时的假设。因此，我们在每次训练D之后训练G几个步骤进行收敛。详细过程在算法1中说明。

## 4 理论基础

我们提供理论分析，说明为什么GAN可以在图上帮助半监督学习。在3.1节中，我们声称工作原理是减少标记节点在密度间隙中的影响。鉴于在深度神经网络训练中直接分析动态障碍的困难，我们基于图拉普拉斯正则化框架进行分析。

定义2.边际节点和内部节点。边际节点M是链接到具有不同标签的节点的节点，而内部节点则不是。形式上，M = {vi |vi∈V∧（∃vj∈V，（vi，vj）∈E∧yi，yj）}，I = V \ M.

假设1.趋同条件。当G收敛时，我们期望它生成链接到附近边缘节点的假样本。更具体地说，让Vд和Eд成为生成的假样本的集合，并生成从生成的节点到附近的原始节点的链接。我们有∀vд∈Vд，（∃vi∈M，（vд，vi）∈Eд）∧（∀（vд，vi）∈Eд，vi∈M）。

图拉普拉斯正则化框架的损失函数如下：

$\mathcal{L}\left(y^{\prime}\right)=\sum_{v_{i} \in V^{L}} \operatorname{loss}\left(y_{i}, y_{i}^{\prime}\right)+\lambda \sum_{v_{i}, v_{j} \in V}^{i \neq j} \alpha_{i j} \cdot n e q\left(y_{i}^{\prime}, y_{j}^{\prime}\right)$

其中y'i表示节点vi的预测标签。损失（·，·）函数测量实际和预测标签之间的监督损失。
neq（·，·）是表示不相等的0或1函数。

$\alpha_{i j}=\tilde{A_{i j}}=\frac{A_{i j}}{\sqrt{\operatorname{deg}(i) \operatorname{deg}(j)}},(i \neq j)$

其中A和A是相邻矩阵和负归一化图拉普拉斯矩阵，de写（i）表示vi的程度。应该注意的是，我们的方程与[40]  - 略有不同，因为我们只考虑显式预测标签而不是标签分布。

归一化是减少边际节点影响的核心。我们的方法很简单：生成假节点，将它们链接到最近的真实节点并解决图拉普拉斯正则化。不允许将伪标签分配给未标记的节点，并且丢失计算仅考虑实际节点之间的边缘。生成之前和之后的唯一区别是边际节点的变化。然后正则化参数αij变化。

### 4.1 证明

我们分析生成的假样本如何帮助获得正确的分类。

推论1.在假设1下，让L（Cдt）和L（Cдt）'在图上（V +Vд，E +Eд）和（V +V'д，E +E'д）失去基础事实。
我们有∀Vд⫌V'д，L（Cдt）<L（Cдt）'，其中Vд和Eд是生成的节点和边缘的集合。

由于αij减小，可以很容易地推导出推论1。随着新假样本的产生，基本事实的丧失继续减少。这表明更有可能获得基本事实。但是，可能存在其他损失减少更多的分类解决方案。因此，我们将进一步证明，我们可以在合理的假设下使用足够的生成样本进行完美分类。