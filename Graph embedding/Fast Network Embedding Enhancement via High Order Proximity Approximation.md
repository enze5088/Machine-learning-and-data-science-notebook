# 基于高阶近似的快速网络嵌入增强

摘要：最近提出了许多网络表示学习方法来学习网络中顶点的向量表示。本文将现有的NRL方法归纳为一个统一的两步框架，包括邻近矩阵的构造和降维。
通过对邻近矩阵构造步骤的分析，得出在建立邻近矩阵时，通过探索高阶近似值可以改进NRL方法。提出了一种隐式逼近高阶近似值的网络嵌入更新算法（neu），该算法具有理论逼近界，可以应用于任何NRL方法中，以提高其性能。我们对多标签分类和链路预测任务进行了实验。
实验结果表明，在所有三个公开数据集上，neu可以在几乎可以忽略运行时间的情况下，对许多NRL方法进行一致且显著的改进。
	本文的源代码可从https://github.com/thunlp/neu获得。

## 1.简介

网络是我们日常生活和学术研究中广泛使用的基本数据类型，如Facebook中的友谊网络和DBLP中的引文网络[Ley，2002]。研究人员为各种网络应用开发了机器学习算法，如顶点分类（Sen等人，2008年）、标签推荐（Tu等人，2014年）、异常检测（Akoglu等人，2015年）和链路预测（Liben Nowell和Kleinberg，2007年）。应用于这些应用程序的大多数监督机器学习算法需要一组信息性功能作为输入【Grover和Leskovec，2016年】。手工制作的功能可能适合需要，但需要大量的人力和专业知识。因此，为了避免特征工程，提高特征的灵活性，提出了通过优化学习学习特征嵌入的表示学习[Bengio等人，2013]。在网络分析方面，近年来，以学习网络顶点分布实值嵌入为目的的网络表示学习（NRL）受到了广泛关注[Perozzi等人，2014；Tang等人，2015b；Cao等人，2015；Grover和Leskovec，2016]。

本文将现有的NRL方法归纳为一个统一的两步框架，包括邻近矩阵的构造和降维。第一步建立一个邻近矩阵m，其中每个条目m i j编码顶点i和j之间的邻近信息。第二步减小邻近矩阵的尺寸以获得网络嵌入。不同的NRL方法采用不同的降维算法，如特征向量计算和SVD分解。我们对第一步即邻近矩阵构造的分析表明，将高阶邻近矩阵编码到邻近矩阵中，可以提高网络嵌入的质量。

然而，对高阶近似值的精确计算是耗时的，因此对于大型网络来说不具有可扩展性。因此，我们只能近似高阶邻近矩阵来学习更好的网络嵌入。为了提高计算效率，我们还试图利用网络表示来编码低阶近邻信息，以避免重复计算。因此，我们提出了一种网络嵌入更新（neu）算法，可以应用于任何NRL方法，以提高其性能。其背后的直觉是，NEU算法处理的嵌入可以隐式逼近高阶近似值，具有理论逼近界，从而获得更好的性能。

我们在三个公开可用的数据集上对多标签分类和链路预测任务进行了实验，以评估网络嵌入的质量。实验结果表明，神经网络增强后，现有NRL方法学习到的网络嵌入在两个评价任务上都能得到一致和显著的改进。此外，NEU的运行时间不到常规NRL方法（如深水和线路）的1%，可以忽略不计。

我们的主要贡献有两方面：1）将现有的NRL方法归纳为一个统一的框架，即邻近矩阵构造和降维，得出网络质量的结论。如果将高阶近似值编码到邻近矩阵中，则可以增强嵌入。

2）我们提出了NEU算法，以提高现有NRL算法学习到的任何网络嵌入的性能。NEU处理的嵌入可以隐式逼近理论界的高阶近似。多标签分类和链路预测的实验结果表明了该算法的有效性和有效性。

在此，我们简要介绍了现有NRL方法，并在下一节对其中一些方法进行了彻底的分析。光谱聚类[TangandLiu,2011]计算顶部-D本征值VEC 归一化拉普拉斯矩阵作为d维网络嵌入的TORS。DeepWalk[Perozzi等人，2014]采用Skip-gram[Mikolov等人，2013]模型，最初用于单词表示。 学习，随机漫步NRL。线[Tang等，2015B]在用于学习大规模网络嵌入的顶点之间的一阶和二阶接近性模型。Grap[CaO等，2015]FA 将不同的k阶邻近矩阵连接起来，并将从每个邻近矩阵中学习到的嵌入连接起来。虽然GraRep比DeepWalk和line获得了更好的性能，但是GraRep仍然存在效率低下的问题。除了上述侧重于网络拓扑的nrl方法之外，研究人员还对网络拓扑进行了扩展。 将元信息(例如文本和标签信息)合并到NRL中的算法。TADW[Yang等人，2015]在矩阵分解框架和M中考虑到文本信息 MDW[Tu等人，2016]学习具有最大边缘约束的半监督网络嵌入。作为另一种半监督的NRL方法，node2vec[Grover和Leskovec， [2016]进一步推广了深度行走与BreadthFirst搜索(BFS)和深度优先搜索(DFS)的随机游走。GCN[Kipf和Wling，2017]，DDRW[Li等人，2016]和Planetoid[Yang等人，2016] 也被提出用于半监督图形嵌入。SDNE[Wang等，2016]采用了NRL的深度神经网络模型。其他扩展包括不对称过渡性[ouetal.，2016]，社区推出器 Ving[Wang等人，2017年]和异源[Tang等人，2015年；Chang等人，2015年；Huang和Mamoulis，2017年；许等人，2017年；Huang等人，2017年]网络嵌入。我们关注的是最普遍的情况 其中NRL方法仅在本文中使用网络拓扑。

2.现有NRL算法的框架

在本节中，我们提出了一个统一的框架，可以涵盖几个代表性的NRL算法，包括光谱聚类[Tang和Liu，2011]，Deepwalk[Perizzi等，2014]，Tadw[Yang等 al.，2015]，一行[Tang等人，2015 b]和GraRep[CaO等人，2015年]。首先，我们对NRL的符号进行了澄清，并对NRL问题进行了形式化描述。然后引入k阶邻近的概念.最后，我们 对基于邻近矩阵分解的NRL框架进行了分析，并证明了上述的NRL方法属于这一范畴。

设G=(V，E)是给定的网络，其中V是顶点集，E是边集。NRL的任务是学习每个顶点v∈V的实值表示RV∈Rd，其中d是嵌入维数。W E假设网络是无权无向的，且不失去一般性，并定义了邻接矩阵Ae∈R_x_v_x_V_x=1，如果(vi，V_j)∈E和Aeij=0则定义为Aeij=1。狄加纳 L矩阵D，∈，R，x，V，x，v，x，x，a=DD1Ae是归一化邻接矩阵，每一行之和等于1。 我们还有Laplacian矩阵Le=DDAe和归一化Laplacian矩阵L=Dd12ldee1-2。

2.1 K阶邻近度